{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short notebook runs ridge regressions on the pre-featurized data matrix using a 5-fold cross-validation approach for all 7 labels used in the study. It saves `.data` files for the cross-validation results (used by Fig 2) and the test set results. It also saves a CSV of test set results that are used for Table S2 and Figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the settings you can adjust when running this notebook:\n",
    "- ``num_threads``: If running on a multi-core machine, change this from ``None`` to an ``int`` in order to set the max number of threads to use\n",
    "- ``subset_[n,feat]``: If you want to subset the training set data for quick tests/debugging, specify that here using the `slice` object. `slice(None)` implies no subsetting of the ~80k observations for each label that are in the training set. `subset_n` slices observations; `subset_feat` subsets features.\n",
    "- ``overwrite``: By default, this code will raise an error if the file you are saving already exists. If you would like to disable that and overwrite existing data files, change `overwrite` to `True`.\n",
    "- ``fixed_lambda``: If True, only run the lambda that was previously chosen. Will throw an error if you haven't already generated a results file.\n",
    "- ``labels_to_run``: By default, this notebook will loop through all the labels. If you would like, you can reduce this list to only loop through a subset of them, by changing ``\"all\"`` to a list of task names, e.g. ``[\"housing\", \"treecover\"]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from mosaiks import transforms\n",
    "from mosaiks.utils import OVERWRITE_EXCEPTION\n",
    "from mosaiks.utils.imports import *\n",
    "from sklearn.metrics import r2_score\n",
    "from threadpoolctl import threadpool_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_threads = None\n",
    "\n",
    "subset_n = slice(None)\n",
    "subset_feat = slice(None)\n",
    "\n",
    "overwrite = None\n",
    "fixed_lambda = False\n",
    "\n",
    "labels_to_run = \"all\"\n",
    "\n",
    "if overwrite is None:\n",
    "    overwrite = os.getenv(\"MOSAIKS_OVERWRITE\", False)\n",
    "if labels_to_run == \"all\":\n",
    "    labels_to_run = c.app_order\n",
    "\n",
    "if num_threads is not None:\n",
    "    threadpool_limits(num_threads)\n",
    "    os.environ[\"NUMBA_NUM_THREADS\"] = str(num_threads)\n",
    "\n",
    "solver = solve.ridge_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Location\n",
    "If you change this location, the template must contain the following sub-strings that get filled in within the loop below:\n",
    "- ``{save_dir}`` The directory in which to save.\n",
    "- ``{reg_type}``: Filled with ``scatter`` for CV and ``testset`` for test set.\n",
    "- ``{label}``: Will be filled with each label you are predicting.\n",
    "- ``{variable}``: The variable name for each label you are predicting.\n",
    "- ``{sampling}``: The sampling scheme for each label you are predicting.\n",
    "- ``{subset}``: Adjusted based on whether you are running on the full dataset or a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "save_patt = join(\n",
    "    \"{save_dir}\",\n",
    "    \"outcomes_{{reg_type}}_obsAndPred_{label}_{variable}_CONTUS_16_640_{sampling}_\"\n",
    "    f\"{c.sampling['n_samples']}_{c.sampling['seed']}_random_features_{c.features['random']['patch_size']}_\"\n",
    "    f\"{c.features['random']['seed']}{{subset}}.data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Random Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our feature matrix `X` for both POP and UAR samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "latlons = {}\n",
    "\n",
    "X[\"UAR\"], latlons[\"UAR\"] = io.get_X_latlon(c, \"UAR\")\n",
    "X[\"POP\"], latlons[\"POP\"] = io.get_X_latlon(c, \"POP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop will:\n",
    "1. Load the appropriate labels\n",
    "2. Merge them with the feature matrix\n",
    "3. Remove test set observations\n",
    "4. Run a ridge regression on the training/validation set, sweeping over a range of possible regularization parameters using 5-fold Cross-Validation and clipping predictions to pre-specified bounds.\n",
    "5. Save the out-of-sample predictions and the observations for use in Figure 2.\n",
    "\n",
    "**Note**: We drop observations for which our labels are missing. For all variables that we model in log-space, we first add 1 to deal with 0-valued observations (except for housing, for which we do not have any 0's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Running regressions for: treecover\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 121.46458005905151\n",
      "Saving validation set results to /data/output/applications/treecover/figures/primary_analysis/outcomes_scatter_obsAndPred_treecover_treecover_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set training time: 25.147928476333618\n",
      "Saving test set results to /data/output/applications/treecover/figures/primary_analysis/outcomes_testset_obsAndPred_treecover_treecover_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n",
      "Full reg time 146.63663625717163\n",
      "*** Running regressions for: elevation\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 80.77733635902405\n",
      "Saving validation set results to /data/output/applications/elevation/figures/primary_analysis/outcomes_scatter_obsAndPred_elevation_meters_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set training time: 24.181716203689575\n",
      "Saving test set results to /data/output/applications/elevation/figures/primary_analysis/outcomes_testset_obsAndPred_elevation_meters_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n",
      "Full reg time 104.98456883430481\n",
      "*** Running regressions for: population\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 58.80880570411682\n",
      "Saving validation set results to /data/output/applications/population/figures/primary_analysis/outcomes_scatter_obsAndPred_population_log_population_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set training time: 13.593569040298462\n",
      "Saving test set results to /data/output/applications/population/figures/primary_analysis/outcomes_testset_obsAndPred_population_log_population_CONTUS_16_640_UAR_100000_0_random_features_3_0.data\n",
      "Full reg time 72.42059087753296\n",
      "*** Running regressions for: nightlights\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 80.82524394989014\n",
      "Saving validation set results to /data/output/applications/nightlights/figures/primary_analysis/outcomes_scatter_obsAndPred_nightlights_log_nightlights_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set training time: 25.60298991203308\n",
      "Saving test set results to /data/output/applications/nightlights/figures/primary_analysis/outcomes_testset_obsAndPred_nightlights_log_nightlights_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Full reg time 106.44975876808167\n",
      "*** Running regressions for: income\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/solve_functions.py:366: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"y_true_test\": np.array(kfold_y_test),\n",
      "/root/capsule/code/mosaiks/solve/solve_functions.py:367: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"y_true_train\": np.array(kfold_y_train),\n",
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 74.96262001991272\n",
      "Saving validation set results to /data/output/applications/income/figures/primary_analysis/outcomes_scatter_obsAndPred_income_income_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Test set training time: 23.47319269180298\n",
      "Saving test set results to /data/output/applications/income/figures/primary_analysis/outcomes_testset_obsAndPred_income_income_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Full reg time 98.45929956436157\n",
      "*** Running regressions for: roads\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 81.54102087020874\n",
      "Saving validation set results to /data/output/applications/roads/figures/primary_analysis/outcomes_scatter_obsAndPred_roads_length_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set training time: 24.554396867752075\n",
      "Saving test set results to /data/output/applications/roads/figures/primary_analysis/outcomes_testset_obsAndPred_roads_length_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Full reg time 106.11688327789307\n",
      "*** Running regressions for: housing\n",
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/capsule/code/mosaiks/solve/solve_functions.py:366: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"y_true_test\": np.array(kfold_y_test),\n",
      "/root/capsule/code/mosaiks/solve/solve_functions.py:367: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"y_true_train\": np.array(kfold_y_train),\n",
      "/root/capsule/code/mosaiks/solve/interpret_results.py:71: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  \"Only one value for hyperparameter number {0} supplied.\".format(ix)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 47.45401883125305\n",
      "Saving validation set results to /data/output/applications/housing/figures/primary_analysis/outcomes_scatter_obsAndPred_housing_log_price_per_sqft_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Test set training time: 11.320044994354248\n",
      "Saving test set results to /data/output/applications/housing/figures/primary_analysis/outcomes_testset_obsAndPred_housing_log_price_per_sqft_CONTUS_16_640_POP_100000_0_random_features_3_0.data\n",
      "Full reg time 58.7882034778595\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "results_dict_test = {}\n",
    "for label in labels_to_run:\n",
    "\n",
    "    print(\"*** Running regressions for: {}\".format(label))\n",
    "\n",
    "    ## Set some label-specific variables\n",
    "    c = io.get_filepaths(c, label)\n",
    "    c_app = getattr(c, label)\n",
    "    sampling_type = c_app[\"sampling\"]  # UAR or POP\n",
    "    this_save_patt = save_patt.format(\n",
    "        subset=\"\",\n",
    "        save_dir=c.fig_dir_prim,\n",
    "        label=label,\n",
    "        variable=c_app[\"variable\"],\n",
    "        sampling=c_app[\"sampling\"],\n",
    "    )\n",
    "\n",
    "    # decide wehether to just test the best lambda(s) or all of them\n",
    "    if fixed_lambda:\n",
    "        best_lambda_fpath = this_save_patt.format(reg_type=\"scatter\", subset=\"\")\n",
    "    else:\n",
    "        best_lambda_fpath = None\n",
    "    this_lambdas = io.get_lambdas(c, label, best_lambda_fpath=best_lambda_fpath)\n",
    "\n",
    "    # determine bounds of predictions\n",
    "    if c_app[\"logged\"]:\n",
    "        bounds = np.array([c_app[\"us_bounds_log_pred\"]])\n",
    "    else:\n",
    "        bounds = np.array([c_app[\"us_bounds_pred\"]])\n",
    "\n",
    "    ## Get save path\n",
    "    if (subset_n != slice(None)) or (subset_feat != slice(None)):\n",
    "        subset_str = \"_subset\"\n",
    "    else:\n",
    "        subset_str = \"\"\n",
    "    save_path_validation = this_save_patt.format(reg_type=\"scatter\", subset=subset_str)\n",
    "    save_path_test = this_save_patt.format(reg_type=\"testset\", subset=subset_str)\n",
    "\n",
    "    if (not overwrite) and (\n",
    "        os.path.isfile(save_path_validation) or os.path.isfile(save_path_test)\n",
    "    ):\n",
    "        raise OVERWRITE_EXCEPTION\n",
    "\n",
    "    ## get X, Y, latlon values of training data\n",
    "    (\n",
    "        this_X,\n",
    "        this_X_test,\n",
    "        this_Y,\n",
    "        this_Y_test,\n",
    "        this_latlons,\n",
    "        this_latlons_test,\n",
    "    ) = parse.merge_dropna_transform_split_train_test(\n",
    "        c, label, X[sampling_type], latlons[sampling_type]\n",
    "    )\n",
    "\n",
    "    ## subset\n",
    "    this_X = this_X[subset_n, subset_feat]\n",
    "    this_X_test = this_X_test[:, subset_feat]\n",
    "    this_Y = this_Y[subset_n]\n",
    "    this_latlons = this_latlons[subset_n]\n",
    "\n",
    "    ## Train model using ridge regression and 5-fold cross-valiation\n",
    "    ## (number of folds can be adjusted using the argument n_folds)\n",
    "    print(\"Training model...\")\n",
    "    import time\n",
    "\n",
    "    st_train = time.time()\n",
    "    kfold_results = solve.kfold_solve(\n",
    "        this_X,\n",
    "        this_Y,\n",
    "        solve_function=solver,\n",
    "        num_folds=c.ml_model[\"n_folds\"],\n",
    "        return_model=True,\n",
    "        lambdas=this_lambdas,\n",
    "        return_preds=True,\n",
    "        svd_solve=False,\n",
    "        clip_bounds=bounds,\n",
    "    )\n",
    "    print(\"\")\n",
    "\n",
    "    # get timing\n",
    "    training_time = time.time() - st_train\n",
    "    print(\"Training time:\", training_time)\n",
    "\n",
    "    ## Store the metrics and the predictions from the best performing model\n",
    "    best_lambda_idx, best_metrics, best_preds = ir.interpret_kfold_results(\n",
    "        kfold_results, \"r2_score\", hps=[(\"lambdas\", c_app[\"lambdas\"])]\n",
    "    )\n",
    "    best_lambda = this_lambdas[best_lambda_idx]\n",
    "\n",
    "    ## combine out-of-sample predictions over folds\n",
    "    preds = np.vstack([solve.y_to_matrix(i) for i in best_preds.squeeze()]).squeeze()\n",
    "    truth = np.vstack(\n",
    "        [solve.y_to_matrix(i) for i in kfold_results[\"y_true_test\"].squeeze()]\n",
    "    ).squeeze()\n",
    "\n",
    "    # get latlons in same shuffled, cross-validated order\n",
    "    ll = this_latlons[\n",
    "        np.hstack([test for train, test in kfold_results[\"cv\"].split(this_latlons)])\n",
    "    ]\n",
    "\n",
    "    data = {\n",
    "        \"truth\": truth,\n",
    "        \"preds\": preds,\n",
    "        \"lon\": ll[:, 1],\n",
    "        \"lat\": ll[:, 0],\n",
    "        \"best_lambda\": best_lambda,\n",
    "    }\n",
    "\n",
    "    ## save validation set predictions\n",
    "    print(\"Saving validation set results to {}\".format(save_path_validation))\n",
    "    with open(save_path_validation, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    results_dict = r2_score(truth, preds)\n",
    "\n",
    "    ## Get test set predictions\n",
    "    st_test = time.time()\n",
    "    holdout_results = solve.single_solve(\n",
    "        this_X,\n",
    "        this_X_test,\n",
    "        this_Y,\n",
    "        this_Y_test,\n",
    "        lambdas=best_lambda,\n",
    "        svd_solve=False,\n",
    "        return_preds=True,\n",
    "        return_model=False,\n",
    "        clip_bounds=bounds,\n",
    "    )\n",
    "\n",
    "    # get timing\n",
    "    test_time = time.time() - st_test\n",
    "    print(\"Test set training time:\", test_time)\n",
    "\n",
    "    ## Save test set predictions\n",
    "    ll = this_latlons_test\n",
    "    data = {\n",
    "        \"truth\": holdout_results[\"y_true_test\"],\n",
    "        \"preds\": holdout_results[\"y_pred_test\"][0][0][0],\n",
    "        \"lon\": ll[:, 1],\n",
    "        \"lat\": ll[:, 0],\n",
    "    }\n",
    "\n",
    "    print(\"Saving test set results to {}\".format(save_path_test))\n",
    "    with open(save_path_test, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    ## Store the R2\n",
    "    results_dict_test[label] = holdout_results[\"metrics_test\"][0][0][0][\"r2_score\"]\n",
    "    print(\"Full reg time\", time.time() - st_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Table S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get save path\n",
    "if (subset_n != slice(None)) or (subset_feat != slice(None)):\n",
    "    subset_str = \"_subset\"\n",
    "else:\n",
    "    subset_str = \"\"\n",
    "\n",
    "fn = Path(c.res_dir) / \"tables\" / \"TableS2\" / f\"TestSetPerformance{subset_str}.csv\"\n",
    "\n",
    "# also save in output folder in case interacting w/ CO capsule w/o access to results\n",
    "fn_output = Path(c.out_dir) / \"cnn_comparison\" / f\"TestSetR2_mosaiks{subset_str}.csv\"\n",
    "\n",
    "if (not overwrite) and subset_str == \"\" and fn.isfile():\n",
    "    raise OVERWRITE_EXCEPTION\n",
    "\n",
    "fn.parent.mkdir(parents=True, exist_ok=True)\n",
    "results_df = pd.DataFrame(\n",
    "    {\"Cross-validation R2\": results_dict, \"Test R2\": results_dict_test}\n",
    ")\n",
    "results_df.index.name = \"label\"\n",
    "results_df.to_csv(fn, index=True)\n",
    "results_df.to_csv(fn_output, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
