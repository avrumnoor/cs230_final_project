{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to create the checkerboard test shown in Fig3 C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the settings you can adjust when running this notebook:\n",
    "- ``num_threads``: If running on a multi-core machine, change this from ``None`` to an ``int`` in order to set the max number of threads to use\n",
    "- ``feattype``: If you want to run this using RGB features rather than RCF, change this from \"random\" to \"rgb\"\n",
    "- ``subset_[n,feat]``: If you want to subset the training set data for quick tests/debugging, specify that here using the `slice` object. `slice(None)` implies no subsetting of the ~80k observations for each label that are in the training set. `subset_n` slices observations; `subset_feat` subsets features.\n",
    "- ``overwrite``: By default, this code will raise an error if the file you are saving already exists. If you would like to disable that and overwrite existing data files, change `overwrite` to `True`.\n",
    "- ``fixed_lambda``: If True, only run the lambda that was previously chosen. Will throw an error if you haven't already generated a results file.\n",
    "- ``labels_to_run``: By default, this notebook will loop through all the labels. If you would like, you can reduce this list to only loop through a subset of them, by changing ``\"all\"`` to a list of task names, e.g. ``[\"housing\", \"treecover\"]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_threads = None\n",
    "\n",
    "feattype = \"random\"\n",
    "# feattype = \"rgb\"\n",
    "\n",
    "subset_n = slice(None)\n",
    "subset_feat = slice(None)\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "fixed_lambda = False\n",
    "\n",
    "labels_to_run = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# Import necessary packages\n",
    "from mosaiks import transforms\n",
    "from mosaiks.utils.imports import *\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "if num_threads is not None:\n",
    "    threadpool_limits(num_threads)\n",
    "    os.environ[\"NUMBA_NUM_THREADS\"] = str(num_threads)\n",
    "\n",
    "if overwrite is None:\n",
    "    overwrite = os.getenv(\"MOSAIKS_OVERWRITE\", False)\n",
    "if labels_to_run == \"all\":\n",
    "    labels_to_run = c.app_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Random Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our feature matrix `X` for both POP and UAR samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "latlons = {}\n",
    "\n",
    "X[\"UAR\"], latlons[\"UAR\"] = io.get_X_latlon(c, \"UAR\")\n",
    "X[\"POP\"], latlons[\"POP\"] = io.get_X_latlon(c, \"POP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop will:\n",
    "1. Load the appropriate labels\n",
    "2. Merge them with the feature matrix\n",
    "3. Remove test set observations\n",
    "4. Split data into 50/50 train/validation sets, using a checkerboard pattern of various size squares. This will cause training data to be closer or further (geographically) to validation data. It will also offset each checkerboard pattern several times to calculate uncertainty in the performance estimate induced by choosing a checkerboard origin.\n",
    "5. Run both RBF smoothing and ridge regression (using RCF features) on each train/validation split.\n",
    "5. Save the out-of-sample predictions for both approaches for use in Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_pos = c.checkerboard[\"num_jitter_positions_sqrt\"]\n",
    "prefix_str = \"checkerboardJitterInterpolation\"\n",
    "if not (subset_n == slice(None) and subset_feat == slice(None)):\n",
    "    prefix_str += \"_SUBSAMPLE\"\n",
    "    if overwrite:\n",
    "        print(\n",
    "            \"Setting overwrite = False because you are working with a subset of the full feature matrix.\"\n",
    "        )\n",
    "    overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels_to_run:\n",
    "\n",
    "    print(\"*** Running regressions for: {}\".format(label))\n",
    "\n",
    "    ## Set some label-specific variables\n",
    "    this_cfg = io.get_filepaths(c, label, feattype=feattype)\n",
    "    c_app = getattr(this_cfg, label)\n",
    "    sampling_type = c_app[\"sampling\"]  # UAR or POP\n",
    "\n",
    "    if c_app[\"logged\"]:\n",
    "        bounds = np.array([c_app[\"us_bounds_log_pred\"]])\n",
    "    else:\n",
    "        bounds = np.array([c_app[\"us_bounds_pred\"]])\n",
    "\n",
    "    # Set solver arguments for image-based features\n",
    "    solver_kwargs_base = {\"return_preds\": True, \"clip_bounds\": bounds}\n",
    "    if fixed_lambda:\n",
    "        best_lambda_fpath = join(\n",
    "            this_cfg.fig_dir_sec,\n",
    "            f\"checkerboardJitterInterpolation_{label}_{c_app['variable']}_{this_cfg.full_suffix_image}.data\",\n",
    "        )\n",
    "        sigmas_rbf = io.get_lambdas(\n",
    "            c,\n",
    "            label,\n",
    "            best_lambda_name=\"best_sigma_interp\",\n",
    "            best_lambda_fpath=best_lambda_fpath,\n",
    "        )\n",
    "    else:\n",
    "        best_lambda_fpath = None\n",
    "        sigmas_rbf = this_cfg.checkerboard[\"sigmas\"]\n",
    "\n",
    "    solver_kwargs_image_CB = {\n",
    "        **solver_kwargs_base,\n",
    "        \"lambdas\": io.get_lambdas(\n",
    "            c,\n",
    "            label,\n",
    "            lambda_name=\"lambdas_checkerboard\",\n",
    "            best_lambda_name=\"best_lambda_rcf\",\n",
    "            best_lambda_fpath=best_lambda_fpath,\n",
    "        ),\n",
    "        \"svd_solve\": False,\n",
    "        \"allow_linalg_warning_instances\": False,\n",
    "        \"solve_function\": solve.ridge_regression,\n",
    "    }\n",
    "\n",
    "    # and for spatial interpolation\n",
    "    solver_kwargs_interpolation_CB = {\n",
    "        **solver_kwargs_base,\n",
    "        \"sigmas\": sigmas_rbf,\n",
    "        \"solve_function\": rbf_interpolate.rbf_interpolate_solve,\n",
    "    }\n",
    "\n",
    "    ## get X, Y, latlon values of training data\n",
    "    (\n",
    "        this_X,\n",
    "        _,\n",
    "        this_Y,\n",
    "        _,\n",
    "        this_latlons,\n",
    "        _,\n",
    "    ) = parse.merge_dropna_transform_split_train_test(\n",
    "        this_cfg, label, X[sampling_type], latlons[sampling_type]\n",
    "    )\n",
    "\n",
    "    ## cast latlons to float32 to reduce footprint of RBF smoothing\n",
    "    this_latlons = this_latlons.astype(np.float32)\n",
    "\n",
    "    ## subset\n",
    "    this_latlons = this_latlons[subset_n]\n",
    "    this_X = this_X[subset_n, subset_feat]\n",
    "    this_Y = this_Y[subset_n]\n",
    "\n",
    "    ## -----------------------------------------------------\n",
    "    # Checkerboard r2 analysis (jitter, sigma-sweep)\n",
    "    ## Lat-lon features are done with density estimation (interpolation)\n",
    "    ## -----------------------------------------------------\n",
    "\n",
    "    # Run regressions with spatial interpolation and RCF features\n",
    "    metrics_checkered = {}\n",
    "    best_hps = {}\n",
    "    for features, task, solver_kwargs, hp_name, best_hp_name in [\n",
    "        (\n",
    "            this_latlons,\n",
    "            \"latlon features sigma tuned\",\n",
    "            solver_kwargs_interpolation_CB,\n",
    "            \"sigmas\",\n",
    "            \"best_sigma_interp\",\n",
    "        ),\n",
    "        (\n",
    "            this_X,\n",
    "            \"image_features\",\n",
    "            solver_kwargs_image_CB,\n",
    "            \"lambdas\",\n",
    "            \"best_lambda_rcf\",\n",
    "        ),\n",
    "    ]:\n",
    "        print(f\"Running {task}...\")\n",
    "        results_checkered = spatial_experiments.checkered_predictions_by_radius(\n",
    "            features,\n",
    "            this_Y,\n",
    "            this_latlons,\n",
    "            this_cfg.checkerboard[\"deltas\"],\n",
    "            this_cfg.plotting[\"extent\"],\n",
    "            crit=[\"r2_score\"],\n",
    "            return_hp_idxs=True,\n",
    "            num_jitter_positions_sqrt=jitter_pos,\n",
    "            **solver_kwargs,\n",
    "        )\n",
    "\n",
    "        metrics_checkered[task] = spatial_experiments.results_to_metrics(\n",
    "            results_checkered\n",
    "        )\n",
    "        best_hps[best_hp_name] = np.array(\n",
    "            [solver_kwargs[hp_name][r[\"hp_idxs_chosen\"][0]] for r in results_checkered]\n",
    "        )\n",
    "\n",
    "    # Plot and save\n",
    "    print(f\"Plotting and saving output to {this_cfg.fig_dir_sec}...\")\n",
    "    spatial_plotter.checkerboard_vs_delta_with_jitter(\n",
    "        metrics_checkered,\n",
    "        best_hps,\n",
    "        this_cfg.checkerboard[\"deltas\"],\n",
    "        \"r2_score\",\n",
    "        val_name=c_app[\"variable\"],\n",
    "        app_name=label,\n",
    "        prefix=prefix_str,\n",
    "        suffix=this_cfg.full_suffix_image,\n",
    "        save_dir=this_cfg.fig_dir_sec,\n",
    "        overwrite=overwrite,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks-env",
   "language": "python",
   "name": "mosaiks-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
