{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity to number of training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to create a plot of R^2 and of MSE as a function of:\n",
    "    1. training sample size\n",
    "    2. number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the settings you can adjust when running this notebook:\n",
    "- ``num_threads``: If running on a multi-core machine, change this from ``None`` to an ``int`` in order to set the max number of threads to use\n",
    "- ``feattype``: If you want to run this using RGB features rather than RCF, change this from \"random\" to \"rgb\"\n",
    "- ``subset_[n,feat]``: If you want to subset the training set data for quick tests/debugging, specify that here using the `slice` object. `slice(None)` implies no subsetting of the ~80k observations for each label that are in the training set. `subset_n` slices observations; `subset_feat` subsets features.\n",
    "- ``overwrite``: By default, this code will raise an error if the file you are saving already exists. If you would like to disable that and overwrite existing data files, change `overwrite` to `True`.\n",
    "- ``fixed_lambda``: If True, only run the lambda that was previously chosen. Will throw an error if you haven't already generated a results file.\n",
    "- ``labels_to_run``: By default, this notebook will loop through all the labels. If you would like, you can reduce this list to only loop through a subset of them, by changing ``\"all\"`` to a list of task names, e.g. ``[\"housing\", \"treecover\"]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_threads = None\n",
    "\n",
    "feattype = \"random\"\n",
    "# feattype = \"rgb\"\n",
    "\n",
    "subset_n = slice(None)\n",
    "subset_feat = slice(None)\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "fixed_lambda = False\n",
    "\n",
    "labels_to_run = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "# Import necessary packages\n",
    "from mosaiks import transforms\n",
    "from mosaiks.utils.imports import *\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "if num_threads is not None:\n",
    "    threadpool_limits(num_threads)\n",
    "    os.environ[\"NUMBA_NUM_THREADS\"] = str(num_threads)\n",
    "\n",
    "if labels_to_run == \"all\":\n",
    "    labels_to_run = c.app_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Random Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our feature matrix `X` for both POP and UAR samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "\n",
    "X[\"UAR\"], _ = io.get_X_latlon(c, \"UAR\")\n",
    "X[\"POP\"], _ = io.get_X_latlon(c, \"POP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop will:\n",
    "1. Load the appropriate labels\n",
    "2. Merge them with the feature matrix\n",
    "3. Remove test set observations\n",
    "4. Run ridge regression on the training/validation set, sweeping over a range of possible regularization parameters using 5-fold Cross-Validation and clipping predictions to pre-specified bounds. It will do this for multiple training set sizes and feature vector lengths.\n",
    "5. Save the out-of-sample predictions and the observations for use in Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samp_vector = c.performance[\"num_samp_vector\"]\n",
    "if subset_n.stop is not None:\n",
    "    num_samp_vector = [s for s in num_samp_vector if s <= subset_n.stop]\n",
    "    if len(num_samp_vector) < 2:\n",
    "        num_samp_vector = [int(subset_n.stop * 0.8 / 2), int(subset_n.stop * 0.8)]\n",
    "\n",
    "num_feat_vector = c.performance[feattype][\"num_feat_vector\"]\n",
    "if subset_feat.stop is not None:\n",
    "    num_feat_vector = [s for s in num_feat_vector if s <= subset_feat.stop]\n",
    "    if len(num_feat_vector) < 2:\n",
    "        num_feat_vector = [int(subset_feat.stop / 2), subset_feat.stop]\n",
    "\n",
    "folds = c.performance[\"folds\"]\n",
    "\n",
    "if not (subset_n == slice(None) and subset_feat == slice(None)):\n",
    "    suffix_str = \"_SUBSAMPLE\"\n",
    "else:\n",
    "    suffix_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels_to_run:\n",
    "\n",
    "    print(\"*** Running regressions for: {}\".format(label))\n",
    "\n",
    "    ## Set some label-specific variables\n",
    "    this_cfg = io.get_filepaths(c, label, feattype=feattype)\n",
    "    c_app = getattr(this_cfg, label)\n",
    "    sampling_type = c_app[\"sampling\"]  # UAR or POP\n",
    "\n",
    "    if c_app[\"logged\"]:\n",
    "        bounds = np.array([c_app[\"us_bounds_log_pred\"]])\n",
    "    else:\n",
    "        bounds = np.array([c_app[\"us_bounds_pred\"]])\n",
    "\n",
    "    if fixed_lambda:\n",
    "        best_lambda_fpath_base = join(\n",
    "            this_cfg.fig_dir_sec,\n",
    "            f\"r2_score_vs_{{type}}size_{label}_{c_app['variable']}_{this_cfg.full_suffix}.data\",\n",
    "        )\n",
    "        best_lambda_fpath_numSamp = best_lambda_fpath_base.format(type=\"train\")\n",
    "        best_lambda_fpath_numFeat = best_lambda_fpath_base.format(type=\"feat\")\n",
    "    else:\n",
    "        best_lambda_fpath_numSamp = best_lambda_fpath_numFeat = None\n",
    "    solver_kwargs_base = {\n",
    "        \"return_preds\": True,\n",
    "        \"svd_solve\": False,\n",
    "        \"clip_bounds\": bounds,\n",
    "    }\n",
    "\n",
    "    solver_kwargs_numSamp = {\n",
    "        **solver_kwargs_base,\n",
    "        \"lambdas\": io.get_lambdas(\n",
    "            c, label, best_lambda_fpath=best_lambda_fpath_numSamp\n",
    "        ),\n",
    "    }\n",
    "    solver_kwargs_numFeat = {\n",
    "        **solver_kwargs_base,\n",
    "        \"lambdas\": io.get_lambdas(\n",
    "            c, label, best_lambda_fpath=best_lambda_fpath_numFeat\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    ## get X, Y, latlon values of training data\n",
    "    this_X, _, this_Y, _, _, _ = parse.merge_dropna_transform_split_train_test(\n",
    "        this_cfg, label, X[sampling_type], X[sampling_type].iloc[:, :2]\n",
    "    )\n",
    "\n",
    "    ## subset\n",
    "    this_X = this_X[subset_n, subset_feat]\n",
    "    this_Y = this_Y[subset_n]\n",
    "\n",
    "    ## --------------------------------------------------\n",
    "    ## Performance vs. train sample size\n",
    "    ## --------------------------------------------------\n",
    "    (\n",
    "        idxs_by_num_samples,\n",
    "        results_by_num_samples,\n",
    "        predictions_by_num_samples,\n",
    "        num_samples_taken,\n",
    "    ) = model_experiments.performance_by_num_train_samples(\n",
    "        this_X, this_Y, num_samp_vector, folds, **solver_kwargs_numSamp\n",
    "    )\n",
    "    best_lambdas_by_num_samples = np.asarray(solver_kwargs_numSamp[\"lambdas\"])[\n",
    "        idxs_by_num_samples.squeeze()\n",
    "    ]\n",
    "\n",
    "    ## --------------------------------------------------\n",
    "    ## Performance vs. number of features\n",
    "    ## --------------------------------------------------\n",
    "    (\n",
    "        idxs_by_num_feat,\n",
    "        results_by_num_feat,\n",
    "        preds_by_num_feat,\n",
    "    ) = model_experiments.performance_by_num_features(\n",
    "        this_X, this_Y, num_feat_vector, num_folds=folds, **solver_kwargs_numFeat\n",
    "    )\n",
    "    best_lambdas_by_num_feat = np.asarray(solver_kwargs_numFeat[\"lambdas\"])[\n",
    "        idxs_by_num_feat.squeeze()\n",
    "    ]\n",
    "\n",
    "    ## --------------------------------------------------\n",
    "    ## Plotting and saving\n",
    "    ## --------------------------------------------------\n",
    "    print(f\"Plotting and saving output to {this_cfg.fig_dir_sec}...\")\n",
    "    for crit in [\"mse\", \"r2_score\"]:\n",
    "        if len(this_Y.shape) == 1:\n",
    "            crits = [crit]\n",
    "        else:\n",
    "            crits = [crit] * this_Y.shape[1]\n",
    "        for plot in (\n",
    "            (\n",
    "                results_by_num_samples,\n",
    "                best_lambdas_by_num_samples,\n",
    "                \"_vs_trainsize\",\n",
    "                num_samples_taken,\n",
    "                \"train set size\",\n",
    "            ),\n",
    "            (\n",
    "                results_by_num_feat,\n",
    "                best_lambdas_by_num_feat,\n",
    "                \"_vs_featsize\",\n",
    "                num_feat_vector,\n",
    "                \"number of features\",\n",
    "            ),\n",
    "        ):\n",
    "            prefix_str = crit + plot[2] + suffix_str\n",
    "            plots.metrics_vs_size(\n",
    "                plot[0],\n",
    "                plot[1],\n",
    "                num_folds=folds,\n",
    "                val_names=c_app[\"variable\"],\n",
    "                num_vector=plot[3],\n",
    "                xtitle=plot[4],\n",
    "                crits=crits,\n",
    "                app_name=label,\n",
    "                prefix=prefix_str,\n",
    "                suffix=this_cfg.full_suffix,\n",
    "                save_dir=this_cfg.fig_dir_sec,\n",
    "                overwrite=overwrite,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mosaiks-env]",
   "language": "python",
   "name": "conda-env-mosaiks-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
