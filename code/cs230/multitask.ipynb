{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a01765",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "So note that we have two different sampling methods, \"UAR\" and \"POP\", and the labels we have for our 7 tasks are split between them. Thus, we must train on two different image datasets at once.\n",
    "\n",
    "Our multitask model will also have 7 heads, so we must edit our ResNet18 to accomplish that\n",
    "\n",
    "We should also save the model parameters for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f960a3",
   "metadata": {},
   "source": [
    "## Creating our training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cda2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env variable MOSAIKS_HOME not defined; setting to: \"/home/ubuntu/cs230/mosaiks-paper\"\n",
      "If not desired, please reset os.environ[\"MOSAIKS_NAME\"]\n"
     ]
    }
   ],
   "source": [
    "import io as python_io\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from mosaiks import config as c\n",
    "from mosaiks import transforms as m_transforms\n",
    "from mosaiks.featurization import RemoteSensingSubgridDataset, chunks\n",
    "from mosaiks.utils import io, spatial\n",
    "from mosaiks.solve import data_parser as parse\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm.contrib import tzip\n",
    "import torch.nn.functional as F\n",
    "import uuid\n",
    "import skimage.io\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d10e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_UAR = [\"treecover\", \"elevation\", \"population\",]\n",
    "tasks_POP = [\"nightlights\", \"income\", \"roads\", \"housing\",]\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    \"treecover\",\n",
    "    \"elevation\",\n",
    "    \"population\",\n",
    "    \"nightlights\",\n",
    "    \"income\",\n",
    "    \"roads\",\n",
    "    \"housing\",\n",
    "]\n",
    "\n",
    "data_home = Path(c.data_dir) / \"raw\" / \"imagery\"\n",
    "data_home_UAR = data_home / \"CONTUS_UAR\"\n",
    "data_home_POP = data_home / \"CONTUS_POP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a32dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_labels(task):\n",
    "    c_local = io.get_filepaths(c, task)\n",
    "    c_app = getattr(c_local, task)\n",
    "    Y = io.get_Y(c_local, c_app[\"colname\"])\n",
    "    lons, lats = spatial.ids_to_ll(\n",
    "        Y.index,\n",
    "        c.grid_dir,\n",
    "        c_local.grid[\"area\"],\n",
    "        c_local.images[\"zoom_level\"],\n",
    "        c_local.images[\"n_pixels\"],\n",
    "    )\n",
    "    latlons = np.vstack((np.array(lats), np.array(lons))).T.astype(\"float64\")\n",
    "    ids, Y, latlons = m_transforms.dropna_and_transform(\n",
    "        Y.index.values, Y.values, latlons, c_app\n",
    "    )\n",
    "    return Y, latlons, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(ids, Y, ratio=0.8):\n",
    "    seed = 0\n",
    "    r = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    n = ids.shape[0]\n",
    "    \n",
    "    test_n = round((1 - ratio) * n)\n",
    "    train_n = n - test_n\n",
    "    \n",
    "    shuffled_idx = r.choice(n, n, replace=False)\n",
    "    train_idx = shuffled_idx[:train_n]\n",
    "    test_idx = shuffled_idx[train_n:]\n",
    "    \n",
    "    return ids[train_idx], Y[train_idx], ids[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be43ca5",
   "metadata": {},
   "source": [
    "This code loads labels for each task based on sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6148bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treecover</th>\n",
       "      <th>elevation</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,105</th>\n",
       "      <td>91.223158</td>\n",
       "      <td>1462.463364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1067</th>\n",
       "      <td>11.715897</td>\n",
       "      <td>1919.119465</td>\n",
       "      <td>2.234753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1814.329174</td>\n",
       "      <td>0.385035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1219</th>\n",
       "      <td>0.162632</td>\n",
       "      <td>2079.739485</td>\n",
       "      <td>0.010085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,122</th>\n",
       "      <td>89.316842</td>\n",
       "      <td>1544.912699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,76</th>\n",
       "      <td>96.171579</td>\n",
       "      <td>156.416732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,914</th>\n",
       "      <td>0.003158</td>\n",
       "      <td>1534.612079</td>\n",
       "      <td>1.980177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1524.94773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.260728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,991</th>\n",
       "      <td>9.626745</td>\n",
       "      <td>2071.3507</td>\n",
       "      <td>1.130115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           treecover    elevation population\n",
       "id                                          \n",
       "1000,105   91.223158  1462.463364        NaN\n",
       "1000,1067  11.715897  1919.119465   2.234753\n",
       "1000,1080        0.0  1814.329174   0.385035\n",
       "1000,1219   0.162632  2079.739485   0.010085\n",
       "1000,122   89.316842  1544.912699        NaN\n",
       "...              ...          ...        ...\n",
       "999,76     96.171579   156.416732        NaN\n",
       "999,914     0.003158  1534.612079   1.980177\n",
       "999,942          0.0   1524.94773        NaN\n",
       "999,949          0.0  1430.260728        NaN\n",
       "999,991     9.626745    2071.3507   1.130115\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nightlights</th>\n",
       "      <th>income</th>\n",
       "      <th>roads</th>\n",
       "      <th>housing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53277.708883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1457</th>\n",
       "      <td>2.793769</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>5856.211968</td>\n",
       "      <td>5.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1458</th>\n",
       "      <td>2.374133</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>3708.122387</td>\n",
       "      <td>5.144845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1459</th>\n",
       "      <td>2.813775</td>\n",
       "      <td>62022.434843</td>\n",
       "      <td>5458.893879</td>\n",
       "      <td>5.091291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1463</th>\n",
       "      <td>1.613503</td>\n",
       "      <td>61151.985279</td>\n",
       "      <td>2711.385912</td>\n",
       "      <td>5.042022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,962</th>\n",
       "      <td>3.164506</td>\n",
       "      <td>74250.611331</td>\n",
       "      <td>6009.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,963</th>\n",
       "      <td>2.678835</td>\n",
       "      <td>73374.52862</td>\n",
       "      <td>5856.974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,964</th>\n",
       "      <td>3.302048</td>\n",
       "      <td>73351.713585</td>\n",
       "      <td>8132.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,965</th>\n",
       "      <td>3.07826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6581.161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389,715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59210.540606</td>\n",
       "      <td>9012.88271</td>\n",
       "      <td>8.051807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nightlights        income        roads   housing\n",
       "id                                                        \n",
       "1000,114          0.0  53277.708883          0.0       NaN\n",
       "1000,1457    2.793769       85920.0  5856.211968  5.003458\n",
       "1000,1458    2.374133       85920.0  3708.122387  5.144845\n",
       "1000,1459    2.813775  62022.434843  5458.893879  5.091291\n",
       "1000,1463    1.613503  61151.985279  2711.385912  5.042022\n",
       "...               ...           ...          ...       ...\n",
       "999,962      3.164506  74250.611331      6009.25       NaN\n",
       "999,963      2.678835   73374.52862     5856.974       NaN\n",
       "999,964      3.302048  73351.713585     8132.549       NaN\n",
       "999,965       3.07826           NaN     6581.161       NaN\n",
       "1389,715          NaN  59210.540606   9012.88271  8.051807\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_UAR = pd.DataFrame()\n",
    "for task in tasks_UAR:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_UAR.empty:\n",
    "        dfs_UAR = df\n",
    "    else:\n",
    "        dfs_UAR = dfs_UAR.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_UAR)\n",
    "    \n",
    "dfs_POP = pd.DataFrame()\n",
    "for task in tasks_POP:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_POP.empty:\n",
    "        dfs_POP = df\n",
    "    else:\n",
    "        dfs_POP = dfs_POP.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_POP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e60771",
   "metadata": {},
   "source": [
    "Some tasks don't have labels for all images, so we can detect that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e7f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3)\n",
      "(80000, 4)\n",
      "float32\n",
      "float32\n",
      "NaN count in train, task nightlights: 1/80000\n",
      "NaN count in test, task nightlights: 0/20000\n",
      "NaN count in train, task income: 6927/80000\n",
      "NaN count in test, task income: 1696/20000\n",
      "NaN count in train, task roads: 0/80000\n",
      "NaN count in test, task roads: 0/20000\n",
      "NaN count in train, task housing: 38064/80000\n",
      "NaN count in test, task housing: 9581/20000\n"
     ]
    }
   ],
   "source": [
    "(ids_train_UAR, Y_train_UAR, ids_test_UAR, Y_test_UAR) = split_train_test(dfs_UAR.index.to_numpy(), dfs_UAR.loc[:, dfs_UAR.columns != 'id'].to_numpy(dtype='float32'))\n",
    "(ids_train_POP, Y_train_POP, ids_test_POP, Y_test_POP) = split_train_test(dfs_POP.index.to_numpy(), dfs_POP.loc[:, dfs_POP.columns != 'id'].to_numpy(dtype='float32'))\n",
    "\n",
    "print(Y_train_UAR.shape)\n",
    "print(Y_train_POP.shape)\n",
    "print(Y_train_UAR.dtype)\n",
    "print(Y_train_POP.dtype)\n",
    "\n",
    "for i in range(len(tasks_POP)):\n",
    "    print(f\"NaN count in train, task {tasks_POP[i]}: {np.sum(np.isnan(Y_train_POP[:,i]))}/80000\")\n",
    "    print(f\"NaN count in test, task {tasks_POP[i]}: {np.sum(np.isnan(Y_test_POP[:,i]))}/20000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04df7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_inputs(augment):\n",
    "    out = [transforms.ToPILImage(), transforms.CenterCrop(224)]\n",
    "    if augment:\n",
    "        out += [transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.RandomRotation(20)]\n",
    "    out += [transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "    return transforms.Compose(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78990c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_home, Y, ids, batch_size=16, shuffle=True, num_workers=4, augment=False):\n",
    "    transform = transform_img_inputs(augment)\n",
    "    r_grid = RemoteSensingSubgridDataset(data_home, Y, ids, transform=transform)\n",
    "    return torch.utils.data.DataLoader(r_grid, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296abd1",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb9c02",
   "metadata": {},
   "source": [
    "This model is our simple model with a linear head. Note that we have two heads for easier training on UAR tasks and POP tasks, should we choose to train them simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a6ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        #shared part\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        \n",
    "        self.sampling = nn.ModuleList()\n",
    "        self.sampling.add_module('UAR', nn.Linear(num_ftrs, len(tasks_UAR)))\n",
    "        self.sampling.add_module('POP', nn.Linear(num_ftrs, len(tasks_POP)))\n",
    "\n",
    "    def forward(self, X, sampling):\n",
    "        # shared part\n",
    "        resnet_output = self.resnet18(X)\n",
    "\n",
    "        # sampling specific parts\n",
    "        if sampling == 'UAR':\n",
    "            return self.sampling.UAR(resnet_output)\n",
    "        elif sampling == 'POP':\n",
    "            return self.sampling.POP(resnet_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7914ff",
   "metadata": {},
   "source": [
    "This model adds another linear layer with a ReLU before the final outputs. Otherwise, it is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b0d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModelTwo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModelTwo, self).__init__()\n",
    "        #shared part\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        num_hidden = int(num_ftrs / 2)\n",
    "        \n",
    "        self.sampling = nn.ModuleList()\n",
    "        self.sampling.add_module('UAR', nn.Sequential(nn.Linear(num_ftrs, num_hidden), nn.ReLU(), nn.Linear(num_hidden, len(tasks_UAR))))\n",
    "        self.sampling.add_module('POP', nn.Sequential(nn.Linear(num_ftrs, num_hidden), nn.ReLU(), nn.Linear(num_hidden, len(tasks_POP))))\n",
    "\n",
    "    def forward(self, X, sampling):\n",
    "        # shared part\n",
    "        resnet_output = self.resnet18(X)\n",
    "\n",
    "        # sampling specific parts\n",
    "        if sampling == 'UAR':\n",
    "            return self.sampling.UAR(resnet_output)\n",
    "        elif sampling == 'POP':\n",
    "            return self.sampling.POP(resnet_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c64ff",
   "metadata": {},
   "source": [
    "This is a wrapper that we actually use for our loss function. This implements Uncertainty Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7e4091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModelWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModelWrapper, self).__init__()\n",
    "        self.log_vars = nn.Parameter(torch.zeros((len(tasks))))\n",
    "        \n",
    "    def forward(self, outputs, labels, criterion, sampling):\n",
    "        mask = (torch.isnan(labels) == False)\n",
    "        outputs = outputs * mask\n",
    "        labels = torch.nan_to_num(labels, nan=0.0)\n",
    "        if sampling == 'UAR':\n",
    "            loss_treecover = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_treecover = torch.exp(-self.log_vars[0])\n",
    "            loss_treecover = precision_treecover * loss_treecover + self.log_vars[0]\n",
    "            \n",
    "            loss_elevation = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_elevation = torch.exp(-self.log_vars[1])\n",
    "            loss_elevation = precision_elevation * loss_elevation + self.log_vars[1]\n",
    "            \n",
    "            loss_population = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_population = torch.exp(-self.log_vars[2])\n",
    "            loss_population = precision_population * loss_population + self.log_vars[2]\n",
    "            \n",
    "            return loss_treecover + loss_elevation + loss_population\n",
    "        elif sampling == \"POP\":\n",
    "            loss_nightlights = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_nightlights = torch.exp(-self.log_vars[3])\n",
    "            loss_nightlights = precision_nightlights * loss_nightlights + self.log_vars[3]\n",
    "            \n",
    "            loss_income = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_income = torch.exp(-self.log_vars[4])\n",
    "            loss_income = precision_income * loss_income + self.log_vars[4]\n",
    "            \n",
    "            loss_roads = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_roads = torch.exp(-self.log_vars[5])\n",
    "            loss_roads = precision_roads * loss_roads + self.log_vars[5]\n",
    "            \n",
    "            loss_housing = criterion(outputs[:,3], labels[:, 3])\n",
    "            precision_housing = torch.exp(-self.log_vars[6])\n",
    "            loss_housing = precision_housing * loss_housing + self.log_vars[6]\n",
    "            \n",
    "            return loss_nightlights + loss_income + loss_roads + loss_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c5ddf",
   "metadata": {},
   "source": [
    "The two cells below just help test to see if the models look correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469ca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = MultiTaskModel().to(device)\n",
    "loss_ft = MultiTaskModelWrapper().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6d35e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "MultiTaskModel                                --                        --\n",
      "â”œâ”€ModuleList: 1-1                             --                        --\n",
      "â”œâ”€ResNet: 1-2                                 [32, 512]                 --\n",
      "â”‚    â””â”€Conv2d: 2-1                            [32, 64, 112, 112]        9,408\n",
      "â”‚    â””â”€BatchNorm2d: 2-2                       [32, 64, 112, 112]        128\n",
      "â”‚    â””â”€ReLU: 2-3                              [32, 64, 112, 112]        --\n",
      "â”‚    â””â”€MaxPool2d: 2-4                         [32, 64, 56, 56]          --\n",
      "â”‚    â””â”€Sequential: 2-5                        [32, 64, 56, 56]          --\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-1                   [32, 64, 56, 56]          73,984\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-2                   [32, 64, 56, 56]          73,984\n",
      "â”‚    â””â”€Sequential: 2-6                        [32, 128, 28, 28]         --\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-3                   [32, 128, 28, 28]         230,144\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-4                   [32, 128, 28, 28]         295,424\n",
      "â”‚    â””â”€Sequential: 2-7                        [32, 256, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-5                   [32, 256, 14, 14]         919,040\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-6                   [32, 256, 14, 14]         1,180,672\n",
      "â”‚    â””â”€Sequential: 2-8                        [32, 512, 7, 7]           --\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-7                   [32, 512, 7, 7]           3,673,088\n",
      "â”‚    â”‚    â””â”€BasicBlock: 3-8                   [32, 512, 7, 7]           4,720,640\n",
      "â”‚    â””â”€AdaptiveAvgPool2d: 2-9                 [32, 512, 1, 1]           --\n",
      "â”‚    â””â”€Identity: 2-10                         [32, 512]                 --\n",
      "â”œâ”€ModuleList: 1-1                             --                        --\n",
      "â”‚    â””â”€Linear: 2-11                           [32, 4]                   2,052\n",
      "===============================================================================================\n",
      "Total params: 11,178,564\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 58.03\n",
      "===============================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.66\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 1335.64\n",
      "===============================================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MultiTaskModelWrapper                    7\n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "resnet18.conv1.weight\n",
      "resnet18.bn1.weight\n",
      "resnet18.bn1.bias\n",
      "resnet18.layer1.0.conv1.weight\n",
      "resnet18.layer1.0.bn1.weight\n",
      "resnet18.layer1.0.bn1.bias\n",
      "resnet18.layer1.0.conv2.weight\n",
      "resnet18.layer1.0.bn2.weight\n",
      "resnet18.layer1.0.bn2.bias\n",
      "resnet18.layer1.1.conv1.weight\n",
      "resnet18.layer1.1.bn1.weight\n",
      "resnet18.layer1.1.bn1.bias\n",
      "resnet18.layer1.1.conv2.weight\n",
      "resnet18.layer1.1.bn2.weight\n",
      "resnet18.layer1.1.bn2.bias\n",
      "resnet18.layer2.0.conv1.weight\n",
      "resnet18.layer2.0.bn1.weight\n",
      "resnet18.layer2.0.bn1.bias\n",
      "resnet18.layer2.0.conv2.weight\n",
      "resnet18.layer2.0.bn2.weight\n",
      "resnet18.layer2.0.bn2.bias\n",
      "resnet18.layer2.0.downsample.0.weight\n",
      "resnet18.layer2.0.downsample.1.weight\n",
      "resnet18.layer2.0.downsample.1.bias\n",
      "resnet18.layer2.1.conv1.weight\n",
      "resnet18.layer2.1.bn1.weight\n",
      "resnet18.layer2.1.bn1.bias\n",
      "resnet18.layer2.1.conv2.weight\n",
      "resnet18.layer2.1.bn2.weight\n",
      "resnet18.layer2.1.bn2.bias\n",
      "resnet18.layer3.0.conv1.weight\n",
      "resnet18.layer3.0.bn1.weight\n",
      "resnet18.layer3.0.bn1.bias\n",
      "resnet18.layer3.0.conv2.weight\n",
      "resnet18.layer3.0.bn2.weight\n",
      "resnet18.layer3.0.bn2.bias\n",
      "resnet18.layer3.0.downsample.0.weight\n",
      "resnet18.layer3.0.downsample.1.weight\n",
      "resnet18.layer3.0.downsample.1.bias\n",
      "resnet18.layer3.1.conv1.weight\n",
      "resnet18.layer3.1.bn1.weight\n",
      "resnet18.layer3.1.bn1.bias\n",
      "resnet18.layer3.1.conv2.weight\n",
      "resnet18.layer3.1.bn2.weight\n",
      "resnet18.layer3.1.bn2.bias\n",
      "resnet18.layer4.0.conv1.weight\n",
      "resnet18.layer4.0.bn1.weight\n",
      "resnet18.layer4.0.bn1.bias\n",
      "resnet18.layer4.0.conv2.weight\n",
      "resnet18.layer4.0.bn2.weight\n",
      "resnet18.layer4.0.bn2.bias\n",
      "resnet18.layer4.0.downsample.0.weight\n",
      "resnet18.layer4.0.downsample.1.weight\n",
      "resnet18.layer4.0.downsample.1.bias\n",
      "resnet18.layer4.1.conv1.weight\n",
      "resnet18.layer4.1.bn1.weight\n",
      "resnet18.layer4.1.bn1.bias\n",
      "resnet18.layer4.1.conv2.weight\n",
      "resnet18.layer4.1.bn2.weight\n",
      "resnet18.layer4.1.bn2.bias\n",
      "sampling.UAR.weight\n",
      "sampling.UAR.bias\n",
      "sampling.POP.weight\n",
      "sampling.POP.bias\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_ft, input_size=(32, 3, 224, 224), sampling=\"POP\"))\n",
    "print(summary(loss_ft))\n",
    "for name, param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a62fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    sampling,\n",
    "    model_uuid,\n",
    "    model,\n",
    "    loss_model,\n",
    "    criterion,\n",
    "    train_dataloaders,\n",
    "    test_dataloaders,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mean,\n",
    "    std,\n",
    "    num_epochs=50,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "    use_loss_model = False\n",
    "):\n",
    "    since = time.time()\n",
    "    summary_writer = SummaryWriter(Path(log_loc)/ f\"1234{sampling}\")\n",
    "    global_step = 0\n",
    "    \n",
    "    preds = {}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.debug(\"Using torch.device: {}\".format(device))\n",
    "    logger.debug(\"model uuid: {}\".format(model_uuid))\n",
    "    \n",
    "    task_list = tasks_UAR if sampling == \"UAR\" else tasks_POP\n",
    "    task_num = len(task_list)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        logger.debug(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        logger.debug(\"-\" * 10)\n",
    "        \n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            all_labels = {sample : [] for sample in tasks}\n",
    "            all_predictions = {sample : [] for sample in tasks}\n",
    "            all_ids = {sample : [] for sample in tasks}\n",
    "\n",
    "            counter = 0\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            summary_writer.add_scalar(\n",
    "                tag=\"learning_rate\", scalar_value=lr, global_step=global_step\n",
    "            )\n",
    "\n",
    "            dataloaders = train_dataloaders if phase == \"train\" else test_dataloaders\n",
    "\n",
    "            num_batches = len(dataloaders[sampling])\n",
    "            logger.debug(\"Total batches: {}\".format(num_batches))\n",
    "            end_time = time.time()\n",
    "            debug_time = time.time()\n",
    "            \n",
    "            loss_sum = 0\n",
    "            \n",
    "            for ids, inputs, labels in tqdm(dataloaders[sampling]):\n",
    "                counter += 1\n",
    "                global_step += 1\n",
    "                    \n",
    "                for i in range(task_num):\n",
    "                    all_labels[task_list[i]] += list(labels.numpy()[:,i])\n",
    "                    all_ids[task_list[i]] += list(ids)\n",
    "                \n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model.forward(inputs, sampling)\n",
    "\n",
    "                    for i in range(task_num):\n",
    "                        all_predictions[task_list[i]] += list(outputs.detach().cpu().numpy()[:,i])\n",
    "                        \n",
    "                    if not use_loss_model:\n",
    "                        mask = (torch.isnan(labels) == False)\n",
    "                        outputs = outputs * mask\n",
    "                        labels = torch.nan_to_num(labels, nan=0.0)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        weight = F.softmax(torch.randn(task_num), dim=-1).to(device)\n",
    "                        if sampling == \"UAR\":\n",
    "                            reg_2 = torch.norm(model.sampling.UAR[3].weight, p=1)\n",
    "                        else:\n",
    "                            reg_2 = torch.norm(model.sampling.POP[3].weight, p=1)\n",
    "                        final_loss = torch.sum(loss*weight) + reg_2 * 0.01\n",
    "                        \n",
    "                    else:\n",
    "                        if sampling == \"UAR\":\n",
    "                            reg = torch.norm(model.sampling.UAR.weight, p=1)\n",
    "                        else:\n",
    "                            reg = torch.norm(model.sampling.POP.weight, p=1)\n",
    "                        loss = loss_model.forward(outputs, labels, criterion, \"UAR\")\n",
    "                        final_loss = loss + reg * 0.1\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        summary_writer.add_scalar(\n",
    "                            tag=\"train_loss\",\n",
    "                            scalar_value=loss.item(),\n",
    "                            global_step=global_step,\n",
    "                        )\n",
    "                    else:\n",
    "                        summary_writer.add_scalar(\n",
    "                            tag=\"val_loss\",\n",
    "                            scalar_value=loss.item(),\n",
    "                            global_step=global_step,\n",
    "                        )\n",
    "                loss_sum += loss.item()\n",
    "                \n",
    "            logger.debug(\"Time for {} batches: {}. Avg loss: {}\".format(num_batches, time.time() - debug_time, loss_sum / num_batches))\n",
    "            loss_sum = 0\n",
    "            debug_time = time.time()\n",
    "\n",
    "            # Testin some stuff here\n",
    "            r2_scores = []\n",
    "            for i in range(task_num):\n",
    "                samp = task_list[i]\n",
    "                temp_labels = np.array(all_labels[samp])\n",
    "                temp_pred = np.array(all_predictions[samp])\n",
    "\n",
    "                mask = (np.isnan(temp_labels) == False)\n",
    "                temp_pred = temp_pred[mask]\n",
    "                temp_labels = temp_labels[mask]\n",
    "\n",
    "                temp_pred = temp_pred * std[i] + mean[i]\n",
    "                temp_labels = temp_labels * std[i] + mean[i]\n",
    "\n",
    "                r2_score = sklearn.metrics.r2_score(temp_labels, temp_pred)\n",
    "                r2_scores.append(r2_score)\n",
    "                logger.debug(\"Aggregate R2 for {0}: {1}\".format(samp, r2_score))\n",
    "            \n",
    "            r2_scores = np.array(r2_scores)\n",
    "            \n",
    "            preds[phase] = (all_labels, all_predictions, all_ids)\n",
    "\n",
    "            bio = python_io.BytesIO()\n",
    "            torch.save(model.state_dict(), bio)\n",
    "            model_checkpoint = {}\n",
    "            model_checkpoint[\"model_bytes\"] = bio.getvalue()\n",
    "            model_checkpoint[\"val_r2\"] = r2_scores\n",
    "            model_checkpoint[\"epoch\"] = epoch\n",
    "            model_checkpoint[\"preds\"] = preds[phase]\n",
    "            model_checkpoint[\"domain_names\"] = tasks_UAR\n",
    "\n",
    "            if save_dir is not None:\n",
    "                this_save_path = (\n",
    "                    save_dir\n",
    "                    / str(model_uuid)\n",
    "                    / \"checkpoints\"\n",
    "                    / phase\n",
    "                    / f\"epoch_{epoch}_UAR.pickle\"\n",
    "                )\n",
    "                this_save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "                with open(this_save_path, \"wb\") as f:\n",
    "                    pickle.dump(model_checkpoint, f, protocol=4)\n",
    "                \n",
    "            if phase == \"test\":\n",
    "                scheduler.step()\n",
    "\n",
    "            logger.debug(\n",
    "                \"Epoch {0} Phase {1} complete\".format(epoch + 1, phase)\n",
    "            )\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    logger.debug(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad30b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    sampling,\n",
    "    model_uuid,\n",
    "    ids_train,\n",
    "    Y_train,\n",
    "    ids_test,\n",
    "    Y_test,\n",
    "    model,\n",
    "    data_home,\n",
    "    loss,\n",
    "    num_epochs=50,\n",
    "    initial_lr=0.001,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "    batch_size=16,\n",
    "):\n",
    "    mean = np.nanmean(Y_train, axis=0)\n",
    "    std = np.nanstd(Y_train, axis=0)\n",
    "    Y_train = (Y_train - mean) / std\n",
    "    Y_test = (Y_test - mean) / std\n",
    "    \n",
    "    train_dataloaders = {}\n",
    "    test_dataloaders = {}\n",
    "    \n",
    "    train_dataloaders[sampling] = get_dataloader(\n",
    "        data_home,\n",
    "        Y_train,\n",
    "        ids_train,\n",
    "        batch_size=batch_size,\n",
    "        augment=True)\n",
    "    \n",
    "    test_dataloaders[sampling] = get_dataloader(\n",
    "        data_home,\n",
    "        Y_test,\n",
    "        ids_test,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    if loss == \"mse\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        criterion = torch.nn.L1Loss()\n",
    "        \n",
    "    loss_model = MultiTaskModelWrapper()\n",
    "        \n",
    "    optimizer_ft = torch.optim.SGD(list(model.parameters()) + list(loss_model.parameters()), lr=initial_lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10], gamma=0.5)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    return train_model(\n",
    "        sampling,\n",
    "        model_uuid,\n",
    "        model,\n",
    "        loss_model,\n",
    "        criterion,\n",
    "        train_dataloaders,\n",
    "        test_dataloaders,\n",
    "        optimizer_ft,\n",
    "        scheduler,\n",
    "        mean,\n",
    "        std,\n",
    "        num_epochs=num_epochs,\n",
    "        log_loc=log_loc,\n",
    "        save_dir=save_dir,\n",
    "        use_loss_model=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147f57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 01:22:15.280 | DEBUG    | __main__:train_model:24 - Using torch.device: cuda:0\n",
      "2022-06-01 01:22:15.281 | DEBUG    | __main__:train_model:25 - model uuid: e990d040-0a61-4c10-ace2-8b4c4c4d38a7\n",
      "2022-06-01 01:22:15.282 | DEBUG    | __main__:train_model:31 - Epoch 1/50\n",
      "2022-06-01 01:22:15.283 | DEBUG    | __main__:train_model:32 - ----------\n",
      "2022-06-01 01:22:15.285 | DEBUG    | __main__:train_model:53 - Total batches: 5000\n",
      "  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                | 196/5000 [00:41<16:51,  4.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_uuid \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\n\u001b[0;32m----> 2\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUAR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uuid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids_train_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids_test_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_test_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMultiTaskModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(sampling, model_uuid, ids_train, Y_train, ids_test, Y_test, model, data_home, loss, num_epochs, initial_lr, log_loc, save_dir, batch_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     49\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uuid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_loss_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(sampling, model_uuid, model, loss_model, criterion, train_dataloaders, test_dataloaders, optimizer, scheduler, mean, std, num_epochs, log_loc, save_dir, use_loss_model)\u001b[0m\n\u001b[1;32m     55\u001b[0m debug_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     57\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ids, inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloaders[sampling]):\n\u001b[1;32m     60\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m     global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1182\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1182\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1148\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1148\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1150\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:986\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_uuid = uuid.uuid4()\n",
    "trained_model = run(\n",
    "    \"UAR\",\n",
    "    model_uuid,\n",
    "    ids_train_UAR,\n",
    "    Y_train_UAR,\n",
    "    ids_test_UAR,\n",
    "    Y_test_UAR,\n",
    "    MultiTaskModel(),\n",
    "    data_home_UAR,\n",
    "    'mse',\n",
    "    num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e075540",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiTaskModelTwo:\n\tMissing key(s) in state_dict: \"sampling.UAR.2.weight\", \"sampling.UAR.2.bias\", \"sampling.POP.2.weight\", \"sampling.POP.2.bias\". \n\tUnexpected key(s) in state_dict: \"sampling.UAR.3.weight\", \"sampling.UAR.3.bias\", \"sampling.POP.3.weight\", \"sampling.POP.3.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# torch.save(trained_model_POP.state_dict(), model_param_path)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# now try load\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loaded_model_POP \u001b[38;5;241m=\u001b[39m MultiTaskModelTwo()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mloaded_model_POP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_param_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mosaiks-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1223\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1224\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiTaskModelTwo:\n\tMissing key(s) in state_dict: \"sampling.UAR.2.weight\", \"sampling.UAR.2.bias\", \"sampling.POP.2.weight\", \"sampling.POP.2.bias\". \n\tUnexpected key(s) in state_dict: \"sampling.UAR.3.weight\", \"sampling.UAR.3.bias\", \"sampling.POP.3.weight\", \"sampling.POP.3.bias\". "
     ]
    }
   ],
   "source": [
    "# try save params\n",
    "model_param_path = c.code_dir + \"/cs230/temp_trained_params.pt\"\n",
    "\n",
    "# now try load\n",
    "loaded_model = MultiTaskModel()\n",
    "loaded_model.load_state_dict(torch.load(model_param_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96bf8b",
   "metadata": {},
   "source": [
    "# Generate features for image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7845faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images):\n",
    "    images_resized = []\n",
    "    for im in images:\n",
    "        im = im[:, :, :3]\n",
    "        images_resized.append(\n",
    "            skimage.transform.resize(\n",
    "                im, (224, 224), mode=\"constant\", anti_aliasing=True\n",
    "            )\n",
    "        )\n",
    "    images = np.stack(images_resized, axis=0)\n",
    "    return images\n",
    "\n",
    "def resnet18multitask_features(images, model, batch_size=60, gpu=True):\n",
    "    results = []\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "    for images_chunk in chunks(images, batch_size):\n",
    "        if len(images_chunk.shape) < 4:\n",
    "            images_chunk = images[np.newaxis, :, :, :]\n",
    "        images_chunk = images_chunk.astype(\"float32\").transpose(0, 3, 1, 2)\n",
    "        images_torch = torch.from_numpy(images_chunk)\n",
    "        if gpu:\n",
    "            images_torch = images_torch.cuda()\n",
    "        x = model.resnet18(images_torch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.cpu().data.numpy()\n",
    "        results.append(x)\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.concatenate(results, axis=0)\n",
    "\n",
    "def resnet18_features(images, model, batch_size=60, gpu=True):\n",
    "    results = []\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "    for images_chunk in chunks(images, batch_size):\n",
    "        if len(images_chunk.shape) < 4:\n",
    "            images_chunk = images[np.newaxis, :, :, :]\n",
    "        images_chunk = images_chunk.astype(\"float32\").transpose(0, 3, 1, 2)\n",
    "        images_torch = torch.from_numpy(images_chunk)\n",
    "        if gpu:\n",
    "            images_torch = images_torch.cuda()\n",
    "        x = model.conv1(images_torch)\n",
    "        x = model.bn1(x)\n",
    "        x = model.relu(x)\n",
    "        x = model.maxpool(x)\n",
    "        x = model.layer1(x)\n",
    "        x = model.layer2(x)\n",
    "        x = model.layer3(x)\n",
    "        x = model.layer4(x)\n",
    "        x = model.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.cpu().data.numpy()\n",
    "        results.append(x)\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.concatenate(results, axis=0)\n",
    "\n",
    "def full_featurize(dataset, model_ft, model_type, batch_size, num_workers):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "    output_features = []\n",
    "    data = {}\n",
    "    ids = []\n",
    "    print(len(dataloader))\n",
    "    for j, what in tqdm(enumerate(dataloader)):\n",
    "        i, X_batch = what[:2]\n",
    "        t = time.time()\n",
    "        X_batch = resize_images(X_batch.numpy())\n",
    "        if model_type == 'resnet152':\n",
    "            X_features = resnet152_features(X_batch, model_ft)\n",
    "        elif model_type == 'resnet18multitask':\n",
    "            X_features = resnet18multitask_features(X_batch, model_ft)\n",
    "        else:\n",
    "            X_features = resnet18_features(X_batch, model_ft)\n",
    "        e = time.time()\n",
    "        output_features.append(X_features)\n",
    "    bio_features = python_io.BytesIO()\n",
    "    np.save(bio_features, np.vstack(output_features))\n",
    "    data[\"X\"] = bio_features.getvalue()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f91fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88263999 0.66210188 0.66960459]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../../data/int/deep_models/d1c51538-7ca9-4cc6-8d6e-ea6e967ce077/checkpoints/test/epoch_45_UAR.pickle\"\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_checkpoint = pickle.load(f)\n",
    "print(model_checkpoint[\"val_r2\"])\n",
    "    \n",
    "bio = python_io.BytesIO(model_checkpoint[\"model_bytes\"])\n",
    "multitaskmodel = MultiTaskModel()\n",
    "multitaskmodel.load_state_dict(torch.load(bio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a84e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import mosaiks.featurization\n",
    "importlib.reload(mosaiks.featurization)\n",
    "from mosaiks.featurization import RemoteSensingSubgridDataset\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0593c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"resnet18multitask\"\n",
    "for sample in [\"UAR\", \"POP\"]:\n",
    "\n",
    "    if model_type == \"resnet18multitask\":\n",
    "        model_ft = multitaskmodel\n",
    "        out_file = c.features_dir + f\"/{model_type}_{sample}_v2.pkl\"\n",
    "    else:\n",
    "        model_ft = None\n",
    "        out_file = c.features_dir + f\"/{model_type}_combined_{sample}.pkl\"\n",
    "\n",
    "    subgrid_path = c.grid_paths[sample]\n",
    "\n",
    "    subgrid = np.load(subgrid_path)\n",
    "    ids = subgrid[\"ID\"]\n",
    "    latlons = np.hstack((subgrid[\"lat\"][:, np.newaxis], subgrid[\"lon\"][:, np.newaxis]))\n",
    "\n",
    "    print(c.data_dir + f\"/raw/imagery/CONTUS_{sample}\")\n",
    "\n",
    "    dataset = RemoteSensingSubgridDataset(c.data_dir + f\"/raw/imagery/CONTUS_{sample}\", latlons, ids)\n",
    "    \n",
    "    results_dict = full_featurize(dataset, model_ft, model_type, 128, 4)\n",
    "\n",
    "    # This commented out section will generate features from each individual ResNet18\n",
    "    # dataset = SelfStorageImageDataset(image_dir, ll_formatted)\n",
    "#     print(len(dataset))\n",
    "#     for task in tasks_UAR + tasks_POP:\n",
    "#         print(f\"Running for {task}\")\n",
    "#         resnet18_path = f\"../../data/output/cnn_comparison/resnet18_{task}.pickle\"\n",
    "#         with open(resnet18_path, \"rb\") as f:\n",
    "#             resnet18_results = pickle.load(f)\n",
    "#         resnet18_model = resnet18_results[\"model\"]\n",
    "#         test_r2 = resnet18_results[\"test_r2\"]\n",
    "#         train_r2 = resnet18_results[\"train_r2\"]\n",
    "#         initial_lr = resnet18_results[\"initial_lr\"]\n",
    "#         print(test_r2)\n",
    "#         print(train_r2)\n",
    "#         print(initial_lr)\n",
    "#         model_ft = resnet18_model\n",
    "#         results_dict[f\"X_{task}\"] = full_featurize(dataset, model_ft, model_type, this_c[\"batch_size\"], 4)\n",
    "    results_dict[\"latlon\"] = latlons\n",
    "    results_dict[\"ids_X\"] = ids\n",
    "    with open(out_file, \"wb\") as f:\n",
    "        dill.dump(results_dict, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dae49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_file, \"wb\") as f:\n",
    "    dill.dump(results_dict, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421823f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mosaiks-env)",
   "language": "python",
   "name": "conda_mosaiks-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
