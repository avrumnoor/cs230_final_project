{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a01765",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "So note that we have two different sampling methods, \"UAR\" and \"POP\", and the labels we have for our 7 tasks are split between them. Thus, we must train on two different image datasets at once.\n",
    "\n",
    "Our multitask model will also have 7 heads, so we must edit our ResNet18 to accomplish that\n",
    "\n",
    "We should also save the model parameters for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f960a3",
   "metadata": {},
   "source": [
    "## Creating our training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "82cda2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io as python_io\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from mosaiks import config as c\n",
    "from mosaiks import transforms as m_transforms\n",
    "from mosaiks.featurization import RemoteSensingSubgridDataset\n",
    "from mosaiks.utils import io, spatial\n",
    "from mosaiks.solve import data_parser as parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "183add16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e4d10e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_UAR = [\"treecover\", \"elevation\", \"population\",]\n",
    "tasks_POP = [\"nightlights\", \"income\", \"roads\", \"housing\",]\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    \"treecover\",\n",
    "    \"elevation\",\n",
    "    \"population\",\n",
    "    \"nightlights\",\n",
    "    \"income\",\n",
    "    \"roads\",\n",
    "    \"housing\",\n",
    "]\n",
    "\n",
    "data_home = Path(c.data_dir) / \"raw\" / \"imagery\"\n",
    "data_home_UAR = data_home / \"CONTUS_UAR\"\n",
    "data_home_POP = data_home / \"CONTUS_POP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b2a32dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_labels(task):\n",
    "    c_local = io.get_filepaths(c, task)\n",
    "    c_app = getattr(c_local, task)\n",
    "    Y = io.get_Y(c_local, c_app[\"colname\"])\n",
    "    lons, lats = spatial.ids_to_ll(\n",
    "        Y.index,\n",
    "        c.grid_dir,\n",
    "        c_local.grid[\"area\"],\n",
    "        c_local.images[\"zoom_level\"],\n",
    "        c_local.images[\"n_pixels\"],\n",
    "    )\n",
    "    latlons = np.vstack((np.array(lats), np.array(lons))).T.astype(\"float64\")\n",
    "    ids, Y, latlons = m_transforms.dropna_and_transform(\n",
    "        Y.index.values, Y.values, latlons, c_app\n",
    "    )\n",
    "    return Y, latlons, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e06eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(ids, Y, ratio=0.8):\n",
    "    seed = 0\n",
    "    r = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    n = ids.shape[0]\n",
    "    \n",
    "    test_n = round((1 - ratio) * n)\n",
    "    train_n = n - test_n\n",
    "    \n",
    "    shuffled_idx = r.choice(n, n, replace=False)\n",
    "    train_idx = shuffled_idx[:train_n]\n",
    "    test_idx = shuffled_idx[train_n:]\n",
    "    \n",
    "    return ids[train_idx], Y[train_idx], ids[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0f6148bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treecover</th>\n",
       "      <th>elevation</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,105</th>\n",
       "      <td>91.223158</td>\n",
       "      <td>1462.463364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1067</th>\n",
       "      <td>11.715897</td>\n",
       "      <td>1919.119465</td>\n",
       "      <td>2.234753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1814.329174</td>\n",
       "      <td>0.385035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1219</th>\n",
       "      <td>0.162632</td>\n",
       "      <td>2079.739485</td>\n",
       "      <td>0.010085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,122</th>\n",
       "      <td>89.316842</td>\n",
       "      <td>1544.912699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,76</th>\n",
       "      <td>96.171579</td>\n",
       "      <td>156.416732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,914</th>\n",
       "      <td>0.003158</td>\n",
       "      <td>1534.612079</td>\n",
       "      <td>1.980177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1524.94773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.260728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,991</th>\n",
       "      <td>9.626745</td>\n",
       "      <td>2071.3507</td>\n",
       "      <td>1.130115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           treecover    elevation population\n",
       "id                                          \n",
       "1000,105   91.223158  1462.463364        NaN\n",
       "1000,1067  11.715897  1919.119465   2.234753\n",
       "1000,1080        0.0  1814.329174   0.385035\n",
       "1000,1219   0.162632  2079.739485   0.010085\n",
       "1000,122   89.316842  1544.912699        NaN\n",
       "...              ...          ...        ...\n",
       "999,76     96.171579   156.416732        NaN\n",
       "999,914     0.003158  1534.612079   1.980177\n",
       "999,942          0.0   1524.94773        NaN\n",
       "999,949          0.0  1430.260728        NaN\n",
       "999,991     9.626745    2071.3507   1.130115\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nightlights</th>\n",
       "      <th>income</th>\n",
       "      <th>roads</th>\n",
       "      <th>housing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53277.708883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1457</th>\n",
       "      <td>2.793769</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>5856.211968</td>\n",
       "      <td>5.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1458</th>\n",
       "      <td>2.374133</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>3708.122387</td>\n",
       "      <td>5.144845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1459</th>\n",
       "      <td>2.813775</td>\n",
       "      <td>62022.434843</td>\n",
       "      <td>5458.893879</td>\n",
       "      <td>5.091291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1463</th>\n",
       "      <td>1.613503</td>\n",
       "      <td>61151.985279</td>\n",
       "      <td>2711.385912</td>\n",
       "      <td>5.042022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,962</th>\n",
       "      <td>3.164506</td>\n",
       "      <td>74250.611331</td>\n",
       "      <td>6009.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,963</th>\n",
       "      <td>2.678835</td>\n",
       "      <td>73374.52862</td>\n",
       "      <td>5856.974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,964</th>\n",
       "      <td>3.302048</td>\n",
       "      <td>73351.713585</td>\n",
       "      <td>8132.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,965</th>\n",
       "      <td>3.07826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6581.161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389,715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59210.540606</td>\n",
       "      <td>9012.88271</td>\n",
       "      <td>8.051807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nightlights        income        roads   housing\n",
       "id                                                        \n",
       "1000,114          0.0  53277.708883          0.0       NaN\n",
       "1000,1457    2.793769       85920.0  5856.211968  5.003458\n",
       "1000,1458    2.374133       85920.0  3708.122387  5.144845\n",
       "1000,1459    2.813775  62022.434843  5458.893879  5.091291\n",
       "1000,1463    1.613503  61151.985279  2711.385912  5.042022\n",
       "...               ...           ...          ...       ...\n",
       "999,962      3.164506  74250.611331      6009.25       NaN\n",
       "999,963      2.678835   73374.52862     5856.974       NaN\n",
       "999,964      3.302048  73351.713585     8132.549       NaN\n",
       "999,965       3.07826           NaN     6581.161       NaN\n",
       "1389,715          NaN  59210.540606   9012.88271  8.051807\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_UAR = pd.DataFrame()\n",
    "for task in tasks_UAR:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_UAR.empty:\n",
    "        dfs_UAR = df\n",
    "    else:\n",
    "        dfs_UAR = dfs_UAR.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_UAR)\n",
    "    \n",
    "dfs_POP = pd.DataFrame()\n",
    "for task in tasks_POP:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_POP.empty:\n",
    "        dfs_POP = df\n",
    "    else:\n",
    "        dfs_POP = dfs_POP.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_POP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "30e7f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3)\n",
      "(80000, 4)\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "(ids_train_UAR, Y_train_UAR, ids_test_UAR, Y_test_UAR) = split_train_test(dfs_UAR.index.to_numpy(), dfs_UAR.loc[:, dfs_UAR.columns != 'id'].to_numpy(dtype='float32'))\n",
    "(ids_train_POP, Y_train_POP, ids_test_POP, Y_test_POP) = split_train_test(dfs_POP.index.to_numpy(), dfs_POP.loc[:, dfs_POP.columns != 'id'].to_numpy(dtype='float32'))\n",
    "\n",
    "print(Y_train_UAR.shape)\n",
    "print(Y_train_POP.shape)\n",
    "print(Y_train_UAR.dtype)\n",
    "print(Y_train_POP.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1638fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_inputs():\n",
    "    out = [transforms.ToPILImage(), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "    return transforms.Compose(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "33ed2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_home, Y, ids, batch_size=16, shuffle=True, num_workers=4):\n",
    "    transform = transform_img_inputs()\n",
    "    r_grid = RemoteSensingSubgridDataset(data_home, Y, ids, transform=transform)\n",
    "    return torch.utils.data.DataLoader(r_grid, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296abd1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4d1e9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        #shared part\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        \n",
    "        self.sampling = nn.ModuleList()\n",
    "        self.sampling.add_module('UAR', nn.Linear(num_ftrs, len(tasks_UAR)))\n",
    "        self.sampling.add_module('POP', nn.Linear(num_ftrs, len(tasks_POP)))\n",
    "\n",
    "    def forward(self, X, sampling):\n",
    "        # shared part\n",
    "        resnet_output = self.resnet18(X)\n",
    "\n",
    "        # sampling specific parts\n",
    "        if sampling == 'UAR':\n",
    "            return self.sampling.UAR(resnet_output)\n",
    "        elif sampling == 'POP':\n",
    "            return self.sampling.POP(resnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "601e9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModelWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModelWrapper, self).__init__()\n",
    "        self.log_vars = nn.Parameter(torch.zeros((len(tasks))))\n",
    "        \n",
    "    def forward(self, outputs, labels, criterion, sampling):\n",
    "        mask = torch.isnan(labels)\n",
    "        outputs = outputs * mask\n",
    "        labels = torch.nan_to_num(labels, nan=0.0)\n",
    "        if sampling == 'UAR':\n",
    "            loss_treecover = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_treecover = torch.exp(-self.log_vars[0])\n",
    "            loss_treecover = precision_treecover * loss_treecover + self.log_vars[0]\n",
    "            \n",
    "            loss_elevation = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_elevation = torch.exp(-self.log_vars[1])\n",
    "            loss_elevation = precision_elevation * loss_elevation + self.log_vars[1]\n",
    "            \n",
    "            loss_population = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_population = torch.exp(-self.log_vars[2])\n",
    "            loss_population = precision_population * loss_population + self.log_vars[2]\n",
    "            \n",
    "            return loss_treecover + loss_elevation + loss_population\n",
    "        elif sampling == \"POP\":\n",
    "            loss_nightlights = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_nightlights = torch.exp(-self.log_vars[3])\n",
    "            loss_nightlights = precision_nightlights * loss_nightlights + self.log_vars[3]\n",
    "            \n",
    "            loss_income = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_income = torch.exp(-self.log_vars[4])\n",
    "            loss_income = precision_income * loss_income + self.log_vars[4]\n",
    "            \n",
    "            loss_roads = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_roads = torch.exp(-self.log_vars[5])\n",
    "            loss_roads = precision_roads * loss_roads + self.log_vars[5]\n",
    "            \n",
    "            loss_housing = criterion(outputs[:,3], labels[:, 3])\n",
    "            precision_housing = torch.exp(-self.log_vars[6])\n",
    "            loss_housing = precision_housing * loss_housing + self.log_vars[6]\n",
    "            \n",
    "            return loss_nightlights + loss_income + loss_roads + loss_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "469ca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = MultiTaskModel().to(device)\n",
    "\n",
    "loss_ft = MultiTaskModelWrapper().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dc6d35e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "MultiTaskModel                                --                        --\n",
      "├─ModuleList: 1-1                             --                        --\n",
      "├─ResNet: 1-2                                 [32, 512]                 --\n",
      "│    └─Conv2d: 2-1                            [32, 64, 112, 112]        9,408\n",
      "│    └─BatchNorm2d: 2-2                       [32, 64, 112, 112]        128\n",
      "│    └─ReLU: 2-3                              [32, 64, 112, 112]        --\n",
      "│    └─MaxPool2d: 2-4                         [32, 64, 56, 56]          --\n",
      "│    └─Sequential: 2-5                        [32, 64, 56, 56]          --\n",
      "│    │    └─BasicBlock: 3-1                   [32, 64, 56, 56]          73,984\n",
      "│    │    └─BasicBlock: 3-2                   [32, 64, 56, 56]          73,984\n",
      "│    └─Sequential: 2-6                        [32, 128, 28, 28]         --\n",
      "│    │    └─BasicBlock: 3-3                   [32, 128, 28, 28]         230,144\n",
      "│    │    └─BasicBlock: 3-4                   [32, 128, 28, 28]         295,424\n",
      "│    └─Sequential: 2-7                        [32, 256, 14, 14]         --\n",
      "│    │    └─BasicBlock: 3-5                   [32, 256, 14, 14]         919,040\n",
      "│    │    └─BasicBlock: 3-6                   [32, 256, 14, 14]         1,180,672\n",
      "│    └─Sequential: 2-8                        [32, 512, 7, 7]           --\n",
      "│    │    └─BasicBlock: 3-7                   [32, 512, 7, 7]           3,673,088\n",
      "│    │    └─BasicBlock: 3-8                   [32, 512, 7, 7]           4,720,640\n",
      "│    └─AdaptiveAvgPool2d: 2-9                 [32, 512, 1, 1]           --\n",
      "│    └─Identity: 2-10                         [32, 512]                 --\n",
      "├─ModuleList: 1-1                             --                        --\n",
      "│    └─Linear: 2-11                           [32, 4]                   2,052\n",
      "===============================================================================================\n",
      "Total params: 11,178,564\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 58.03\n",
      "===============================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.66\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 1335.64\n",
      "===============================================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MultiTaskModelWrapper                    7\n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_ft, input_size=(32, 3, 224, 224), sampling=\"POP\"))\n",
    "print(summary(loss_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2270c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    loss_model,\n",
    "    criterion,\n",
    "    train_dataloaders,\n",
    "    test_dataloaders,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mean_UAR,\n",
    "    std_UAR,\n",
    "    mean_POP,\n",
    "    std_POP,\n",
    "    num_epochs=50,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "):\n",
    "    since = time.time()\n",
    "    summary_writer = SummaryWriter(Path(log_loc)/\"1234\")\n",
    "    global_step = 0\n",
    "    \n",
    "    preds = {}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.debug(\"Using torch.device: {}\".format(device))\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.debug(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        logger.debug(\"-\" * 10)\n",
    "        \n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            all_labels = {sample : [] for sample in tasks}\n",
    "            all_predictions = {sample : [] for sample in tasks}\n",
    "            all_ids = {sample : [] for sample in tasks}\n",
    "\n",
    "            counter = 0\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            summary_writer.add_scalar(\n",
    "                tag=\"learning_rate\", scalar_value=lr, global_step=global_step\n",
    "            )\n",
    "\n",
    "            dataloaders = train_dataloaders if phase == \"train\" else test_dataloaders\n",
    "\n",
    "            num_batches = len(dataloaders[\"UAR\"])\n",
    "            logger.debug(\"Total batches: {}\".format(num_batches))\n",
    "            end_time = time.time()\n",
    "            debug_time = time.time()\n",
    "            \n",
    "            for data_UAR, data_POP in tqdm(zip(dataloaders[\"UAR\"], dataloaders[\"POP\"]), total=num_batches):\n",
    "                for sample in [\"UAR\", \"POP\"]:\n",
    "                    if sample == \"UAR\":\n",
    "                        ids, inputs, labels = data_UAR\n",
    "                    elif sample == \"POP\":\n",
    "                        ids, inputs, labels = data_POP\n",
    "\n",
    "                    counter += 1\n",
    "                    global_step += 1\n",
    "\n",
    "                    if sample == \"UAR\":\n",
    "                        for i in range(len(tasks_UAR)):\n",
    "                            all_labels[tasks_UAR[i]] += list(np.vstack(labels.numpy()[:,i]))\n",
    "                            all_ids[tasks_UAR[i]] += list(ids)\n",
    "                    elif sample == \"POP\":\n",
    "                        for i in range(len(tasks_POP)):\n",
    "                            all_labels[tasks_POP[i]] += list(np.vstack(labels.numpy()[:,i]))\n",
    "                            all_ids[tasks_POP[i]] += list(ids)\n",
    "\n",
    "                    inputs = inputs.float()\n",
    "                    labels = labels.float()\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        outputs = model.forward(inputs, sample)\n",
    "\n",
    "                        if sample == \"UAR\":\n",
    "                            for i in range(len(tasks_UAR)):\n",
    "                                all_predictions[tasks_UAR[i]] += list(outputs.detach().cpu().numpy()[:,i])\n",
    "                        elif sample == \"POP\":\n",
    "                            for i in range(len(tasks_POP)):\n",
    "                                all_predictions[tasks_POP[i]] += list(outputs.detach().cpu().numpy()[:,i])\n",
    "\n",
    "                        loss = loss_model.forward(outputs, labels, criterion, sample)\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            summary_writer.add_scalar(\n",
    "                                tag=\"train_loss\",\n",
    "                                scalar_value=loss.item(),\n",
    "                                global_step=global_step,\n",
    "                            )\n",
    "                        else:\n",
    "                            summary_writer.add_scalar(\n",
    "                                tag=\"val_loss\",\n",
    "                                scalar_value=loss.item(),\n",
    "                                global_step=global_step,\n",
    "                            )\n",
    "                yeet = 100\n",
    "                if counter % yeet == 0:\n",
    "                    logger.debug(\"Time for {} batches: {}\".format(yeet, time.time() - debug_time))\n",
    "                    debug_time = time.time()\n",
    "                \n",
    "                # Testin some stuff here\n",
    "                samp = \"treecover\"\n",
    "                std = std_UAR\n",
    "                mean = mean_UAR\n",
    "                \n",
    "                temp_labels = np.array(all_labels[samp])\n",
    "                temp_pred = np.array(all_predictions[samp])\n",
    "                \n",
    "                temp_labels *= std[0]\n",
    "                temp_labels += mean[0]\n",
    "                \n",
    "                temp_pred *= std[0]\n",
    "                temp_labels += mean[0]\n",
    "                \n",
    "                r2_score = sklearn.metrics.r2_score(temp_labels, temp_predictions)\n",
    "                \n",
    "                logger.debug(\n",
    "                    \"Epoch {0} Phase {1} of {2} complete, Aggregate R2 Score of {3}: {4}\".format(\n",
    "                        epoch, phase, sample, samp, r2_score\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    logger.debug(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "cdaebfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    ids_train_UAR,\n",
    "    Y_train_UAR,\n",
    "    ids_test_UAR,\n",
    "    Y_test_UAR,\n",
    "    ids_train_POP,\n",
    "    Y_train_POP,\n",
    "    ids_test_POP,\n",
    "    Y_test_POP,\n",
    "    model,\n",
    "    data_home_UAR,\n",
    "    data_home_POP,\n",
    "    loss,\n",
    "    num_epochs=25,\n",
    "    initial_lr=0.001,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "    batch_size=32,\n",
    "):\n",
    "    mean_UAR = np.nanmean(Y_train_UAR, axis=0)\n",
    "    std_UAR = np.nanstd(Y_train_UAR, axis=0)\n",
    "    Y_train_UAR = (Y_train_UAR - mean_UAR) / std_UAR\n",
    "    Y_test_UAR = (Y_test_UAR - mean_UAR) / std_UAR\n",
    "    \n",
    "    mean_POP = np.nanmean(Y_train_POP, axis=0)\n",
    "    std_POP = np.nanstd(Y_train_POP, axis=0)\n",
    "    Y_train_POP = (Y_train_POP - mean_POP) / std_POP\n",
    "    Y_test_POP = (Y_test_POP - mean_POP) / std_POP\n",
    "    \n",
    "    train_dataloaders = {}\n",
    "    test_dataloaders = {}\n",
    "    \n",
    "    train_dataloaders[\"UAR\"] = get_dataloader(\n",
    "        data_home_UAR,\n",
    "        Y_train_UAR,\n",
    "        ids_train_UAR,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    test_dataloaders[\"UAR\"] = get_dataloader(\n",
    "        data_home_UAR,\n",
    "        Y_test_UAR,\n",
    "        ids_test_UAR,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    train_dataloaders[\"POP\"] = get_dataloader(\n",
    "        data_home_POP,\n",
    "        Y_train_POP,\n",
    "        ids_train_POP,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    train_dataloaders[\"POP\"] = get_dataloader(\n",
    "        data_home_POP,\n",
    "        Y_train_POP,\n",
    "        ids_train_POP,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    if loss == \"mse\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        criterion = torch.nn.L1Loss()\n",
    "        \n",
    "    loss_model = MultiTaskModelWrapper()\n",
    "        \n",
    "    optimizer_ft = torch.optim.SGD(list(model.parameters()) + list(loss_model.parameters()), lr=initial_lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10], gamma=0.5)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    return train_model(\n",
    "        model,\n",
    "        loss_model,\n",
    "        criterion,\n",
    "        train_dataloaders,\n",
    "        test_dataloaders,\n",
    "        optimizer_ft,\n",
    "        scheduler,\n",
    "        mean_UAR,\n",
    "        std_UAR,\n",
    "        mean_POP,\n",
    "        std_POP,\n",
    "        num_epochs=num_epochs,\n",
    "        log_loc=log_loc,\n",
    "        save_dir=save_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1018e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:30:09.106 | DEBUG    | __main__:train_model:23 - Using torch.device: cuda:0\n",
      "2022-05-24 11:30:09.107 | DEBUG    | __main__:train_model:25 - Epoch 1/1\n",
      "2022-05-24 11:30:09.108 | DEBUG    | __main__:train_model:26 - ----------\n",
      "2022-05-24 11:30:09.113 | DEBUG    | __main__:train_model:46 - Total batches: 2500\n",
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss_treecover' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [260]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids_train_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids_test_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_test_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids_train_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids_test_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_test_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMultiTaskModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [259]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(ids_train_UAR, Y_train_UAR, ids_test_UAR, Y_test_UAR, ids_train_POP, Y_train_POP, ids_test_POP, Y_test_POP, model, data_home_UAR, data_home_POP, loss, num_epochs, initial_lr, log_loc, save_dir, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstd_UAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstd_POP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [258]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, loss_model, criterion, train_dataloaders, test_dataloaders, optimizer, scheduler, mean_UAR, std_UAR, mean_POP, std_POP, num_epochs, log_loc, save_dir)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tasks_POP)):\n\u001b[1;32m     84\u001b[0m         all_predictions[tasks_POP[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[:,i])\n\u001b[0;32m---> 86\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     88\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [248]\u001b[0m, in \u001b[0;36mMultiTaskModelWrapper.forward\u001b[0;34m(self, outputs, labels, criterion, sampling)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss_nightlights \u001b[38;5;241m=\u001b[39m criterion(outputs[:,\u001b[38;5;241m0\u001b[39m], labels[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m precision_treecover \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_vars[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m loss_nightlights \u001b[38;5;241m=\u001b[39m precision_treecover \u001b[38;5;241m*\u001b[39m \u001b[43mloss_treecover\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_vars[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     29\u001b[0m loss_income \u001b[38;5;241m=\u001b[39m criterion(outputs[:,\u001b[38;5;241m1\u001b[39m], labels[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     30\u001b[0m precision_income \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_vars[\u001b[38;5;241m4\u001b[39m])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss_treecover' referenced before assignment"
     ]
    }
   ],
   "source": [
    "trained_model = run(ids_train_UAR,\n",
    "    Y_train_UAR,\n",
    "    ids_test_UAR,\n",
    "    Y_test_UAR,\n",
    "    ids_train_POP,\n",
    "    Y_train_POP,\n",
    "    ids_test_POP,\n",
    "    Y_test_POP,\n",
    "    MultiTaskModel(),\n",
    "    data_home_UAR,\n",
    "    data_home_POP,\n",
    "    'mse',\n",
    "    num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try save params\n",
    "model_param_path = code_dir + \"/cs230/temp_trained_params.pt\"\n",
    "torch.save(trained_model.state_dict(), model_param_path)\n",
    "\n",
    "# now try load\n",
    "loaded_model = MultiTaskModel()\n",
    "loaded_model.load_state_dict(torch.load(model_param_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d09848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mosaiks-env)",
   "language": "python",
   "name": "conda_mosaiks-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
