{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a01765",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "So note that we have two different sampling methods, \"UAR\" and \"POP\", and the labels we have for our 7 tasks are split between them. Thus, we must train on two different image datasets at once.\n",
    "\n",
    "Our multitask model will also have 7 heads, so we must edit our ResNet18 to accomplish that\n",
    "\n",
    "We should also save the model parameters for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f960a3",
   "metadata": {},
   "source": [
    "## Creating our training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cda2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env variable MOSAIKS_HOME not defined; setting to: \"/home/ubuntu/cs230/mosaiks-paper\"\n",
      "If not desired, please reset os.environ[\"MOSAIKS_NAME\"]\n"
     ]
    }
   ],
   "source": [
    "import io as python_io\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from mosaiks import config as c\n",
    "from mosaiks import transforms as m_transforms\n",
    "from mosaiks.featurization import RemoteSensingSubgridDataset\n",
    "from mosaiks.utils import io, spatial\n",
    "from mosaiks.solve import data_parser as parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183add16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm.contrib import tzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d10e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_UAR = [\"treecover\", \"elevation\", \"population\",]\n",
    "tasks_POP = [\"nightlights\", \"income\", \"roads\", \"housing\",]\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    \"treecover\",\n",
    "    \"elevation\",\n",
    "    \"population\",\n",
    "    \"nightlights\",\n",
    "    \"income\",\n",
    "    \"roads\",\n",
    "    \"housing\",\n",
    "]\n",
    "\n",
    "data_home = Path(c.data_dir) / \"raw\" / \"imagery\"\n",
    "data_home_UAR = data_home / \"CONTUS_UAR\"\n",
    "data_home_POP = data_home / \"CONTUS_POP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a32dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_labels(task):\n",
    "    c_local = io.get_filepaths(c, task)\n",
    "    c_app = getattr(c_local, task)\n",
    "    Y = io.get_Y(c_local, c_app[\"colname\"])\n",
    "    lons, lats = spatial.ids_to_ll(\n",
    "        Y.index,\n",
    "        c.grid_dir,\n",
    "        c_local.grid[\"area\"],\n",
    "        c_local.images[\"zoom_level\"],\n",
    "        c_local.images[\"n_pixels\"],\n",
    "    )\n",
    "    latlons = np.vstack((np.array(lats), np.array(lons))).T.astype(\"float64\")\n",
    "    ids, Y, latlons = m_transforms.dropna_and_transform(\n",
    "        Y.index.values, Y.values, latlons, c_app\n",
    "    )\n",
    "    return Y, latlons, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(ids, Y, ratio=0.8):\n",
    "    seed = 0\n",
    "    r = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    n = ids.shape[0]\n",
    "    \n",
    "    test_n = round((1 - ratio) * n)\n",
    "    train_n = n - test_n\n",
    "    \n",
    "    shuffled_idx = r.choice(n, n, replace=False)\n",
    "    train_idx = shuffled_idx[:train_n]\n",
    "    test_idx = shuffled_idx[train_n:]\n",
    "    \n",
    "    return ids[train_idx], Y[train_idx], ids[test_idx], Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6148bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treecover</th>\n",
       "      <th>elevation</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,105</th>\n",
       "      <td>91.223158</td>\n",
       "      <td>1462.463364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1067</th>\n",
       "      <td>11.715897</td>\n",
       "      <td>1919.119465</td>\n",
       "      <td>2.234753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1814.329174</td>\n",
       "      <td>0.385035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1219</th>\n",
       "      <td>0.162632</td>\n",
       "      <td>2079.739485</td>\n",
       "      <td>0.010085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,122</th>\n",
       "      <td>89.316842</td>\n",
       "      <td>1544.912699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,76</th>\n",
       "      <td>96.171579</td>\n",
       "      <td>156.416732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,914</th>\n",
       "      <td>0.003158</td>\n",
       "      <td>1534.612079</td>\n",
       "      <td>1.980177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1524.94773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.260728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,991</th>\n",
       "      <td>9.626745</td>\n",
       "      <td>2071.3507</td>\n",
       "      <td>1.130115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           treecover    elevation population\n",
       "id                                          \n",
       "1000,105   91.223158  1462.463364        NaN\n",
       "1000,1067  11.715897  1919.119465   2.234753\n",
       "1000,1080        0.0  1814.329174   0.385035\n",
       "1000,1219   0.162632  2079.739485   0.010085\n",
       "1000,122   89.316842  1544.912699        NaN\n",
       "...              ...          ...        ...\n",
       "999,76     96.171579   156.416732        NaN\n",
       "999,914     0.003158  1534.612079   1.980177\n",
       "999,942          0.0   1524.94773        NaN\n",
       "999,949          0.0  1430.260728        NaN\n",
       "999,991     9.626745    2071.3507   1.130115\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nightlights</th>\n",
       "      <th>income</th>\n",
       "      <th>roads</th>\n",
       "      <th>housing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000,114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53277.708883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1457</th>\n",
       "      <td>2.793769</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>5856.211968</td>\n",
       "      <td>5.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1458</th>\n",
       "      <td>2.374133</td>\n",
       "      <td>85920.0</td>\n",
       "      <td>3708.122387</td>\n",
       "      <td>5.144845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1459</th>\n",
       "      <td>2.813775</td>\n",
       "      <td>62022.434843</td>\n",
       "      <td>5458.893879</td>\n",
       "      <td>5.091291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000,1463</th>\n",
       "      <td>1.613503</td>\n",
       "      <td>61151.985279</td>\n",
       "      <td>2711.385912</td>\n",
       "      <td>5.042022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,962</th>\n",
       "      <td>3.164506</td>\n",
       "      <td>74250.611331</td>\n",
       "      <td>6009.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,963</th>\n",
       "      <td>2.678835</td>\n",
       "      <td>73374.52862</td>\n",
       "      <td>5856.974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,964</th>\n",
       "      <td>3.302048</td>\n",
       "      <td>73351.713585</td>\n",
       "      <td>8132.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999,965</th>\n",
       "      <td>3.07826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6581.161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389,715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59210.540606</td>\n",
       "      <td>9012.88271</td>\n",
       "      <td>8.051807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nightlights        income        roads   housing\n",
       "id                                                        \n",
       "1000,114          0.0  53277.708883          0.0       NaN\n",
       "1000,1457    2.793769       85920.0  5856.211968  5.003458\n",
       "1000,1458    2.374133       85920.0  3708.122387  5.144845\n",
       "1000,1459    2.813775  62022.434843  5458.893879  5.091291\n",
       "1000,1463    1.613503  61151.985279  2711.385912  5.042022\n",
       "...               ...           ...          ...       ...\n",
       "999,962      3.164506  74250.611331      6009.25       NaN\n",
       "999,963      2.678835   73374.52862     5856.974       NaN\n",
       "999,964      3.302048  73351.713585     8132.549       NaN\n",
       "999,965       3.07826           NaN     6581.161       NaN\n",
       "1389,715          NaN  59210.540606   9012.88271  8.051807\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_UAR = pd.DataFrame()\n",
    "for task in tasks_UAR:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_UAR.empty:\n",
    "        dfs_UAR = df\n",
    "    else:\n",
    "        dfs_UAR = dfs_UAR.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_UAR)\n",
    "    \n",
    "dfs_POP = pd.DataFrame()\n",
    "for task in tasks_POP:\n",
    "    Y_task, ll_task, ids_task = grab_labels(task)\n",
    "\n",
    "    Y_and_ids = np.vstack([Y_task, ids_task]).T\n",
    "    \n",
    "    df = pd.DataFrame(Y_and_ids, columns=[task, \"id\"])\n",
    "    df = df.set_index(\"id\")\n",
    "    if dfs_POP.empty:\n",
    "        dfs_POP = df\n",
    "    else:\n",
    "        dfs_POP = dfs_POP.merge(df, how='outer', on='id')\n",
    "        \n",
    "display(dfs_POP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e7f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3)\n",
      "(80000, 4)\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "(ids_train_UAR, Y_train_UAR, ids_test_UAR, Y_test_UAR) = split_train_test(dfs_UAR.index.to_numpy(), dfs_UAR.loc[:, dfs_UAR.columns != 'id'].to_numpy(dtype='float32'))\n",
    "(ids_train_POP, Y_train_POP, ids_test_POP, Y_test_POP) = split_train_test(dfs_POP.index.to_numpy(), dfs_POP.loc[:, dfs_POP.columns != 'id'].to_numpy(dtype='float32'))\n",
    "\n",
    "print(Y_train_UAR.shape)\n",
    "print(Y_train_POP.shape)\n",
    "print(Y_train_UAR.dtype)\n",
    "print(Y_train_POP.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04df7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_inputs():\n",
    "    out = [transforms.ToPILImage(), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "    return transforms.Compose(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78990c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_home, Y, ids, batch_size=16, shuffle=True, num_workers=4):\n",
    "    transform = transform_img_inputs()\n",
    "    r_grid = RemoteSensingSubgridDataset(data_home, Y, ids, transform=transform)\n",
    "    return torch.utils.data.DataLoader(r_grid, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296abd1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a6ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        #shared part\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        \n",
    "        self.sampling = nn.ModuleList()\n",
    "        self.sampling.add_module('UAR', nn.Linear(num_ftrs, len(tasks_UAR)))\n",
    "        self.sampling.add_module('POP', nn.Linear(num_ftrs, len(tasks_POP)))\n",
    "\n",
    "    def forward(self, X, sampling):\n",
    "        # shared part\n",
    "        resnet_output = self.resnet18(X)\n",
    "\n",
    "        # sampling specific parts\n",
    "        if sampling == 'UAR':\n",
    "            return self.sampling.UAR(resnet_output)\n",
    "        elif sampling == 'POP':\n",
    "            return self.sampling.POP(resnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7e4091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModelWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModelWrapper, self).__init__()\n",
    "        self.log_vars = nn.Parameter(torch.zeros((len(tasks))))\n",
    "        \n",
    "    def forward(self, outputs, labels, criterion, sampling):\n",
    "        mask = torch.isnan(labels)\n",
    "        outputs = outputs * mask\n",
    "        labels = torch.nan_to_num(labels, nan=0.0)\n",
    "        if sampling == 'UAR':\n",
    "            loss_treecover = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_treecover = torch.exp(-self.log_vars[0])\n",
    "            loss_treecover = precision_treecover * loss_treecover + self.log_vars[0]\n",
    "            \n",
    "            loss_elevation = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_elevation = torch.exp(-self.log_vars[1])\n",
    "            loss_elevation = precision_elevation * loss_elevation + self.log_vars[1]\n",
    "            \n",
    "            loss_population = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_population = torch.exp(-self.log_vars[2])\n",
    "            loss_population = precision_population * loss_population + self.log_vars[2]\n",
    "            \n",
    "            return loss_treecover + loss_elevation + loss_population\n",
    "        elif sampling == \"POP\":\n",
    "            loss_nightlights = criterion(outputs[:,0], labels[:, 0])\n",
    "            precision_nightlights = torch.exp(-self.log_vars[3])\n",
    "            loss_nightlights = precision_nightlights * loss_nightlights + self.log_vars[3]\n",
    "            \n",
    "            loss_income = criterion(outputs[:,1], labels[:, 1])\n",
    "            precision_income = torch.exp(-self.log_vars[4])\n",
    "            loss_income = precision_income * loss_income + self.log_vars[4]\n",
    "            \n",
    "            loss_roads = criterion(outputs[:,2], labels[:, 2])\n",
    "            precision_roads = torch.exp(-self.log_vars[5])\n",
    "            loss_roads = precision_roads * loss_roads + self.log_vars[5]\n",
    "            \n",
    "            loss_housing = criterion(outputs[:,3], labels[:, 3])\n",
    "            precision_housing = torch.exp(-self.log_vars[6])\n",
    "            loss_housing = precision_housing * loss_housing + self.log_vars[6]\n",
    "            \n",
    "            return loss_nightlights + loss_income + loss_roads + loss_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469ca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = MultiTaskModel().to(device)\n",
    "\n",
    "loss_ft = MultiTaskModelWrapper().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6d35e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "MultiTaskModel                                --                        --\n",
      "├─ModuleList: 1-1                             --                        --\n",
      "├─ResNet: 1-2                                 [32, 512]                 --\n",
      "│    └─Conv2d: 2-1                            [32, 64, 112, 112]        9,408\n",
      "│    └─BatchNorm2d: 2-2                       [32, 64, 112, 112]        128\n",
      "│    └─ReLU: 2-3                              [32, 64, 112, 112]        --\n",
      "│    └─MaxPool2d: 2-4                         [32, 64, 56, 56]          --\n",
      "│    └─Sequential: 2-5                        [32, 64, 56, 56]          --\n",
      "│    │    └─BasicBlock: 3-1                   [32, 64, 56, 56]          73,984\n",
      "│    │    └─BasicBlock: 3-2                   [32, 64, 56, 56]          73,984\n",
      "│    └─Sequential: 2-6                        [32, 128, 28, 28]         --\n",
      "│    │    └─BasicBlock: 3-3                   [32, 128, 28, 28]         230,144\n",
      "│    │    └─BasicBlock: 3-4                   [32, 128, 28, 28]         295,424\n",
      "│    └─Sequential: 2-7                        [32, 256, 14, 14]         --\n",
      "│    │    └─BasicBlock: 3-5                   [32, 256, 14, 14]         919,040\n",
      "│    │    └─BasicBlock: 3-6                   [32, 256, 14, 14]         1,180,672\n",
      "│    └─Sequential: 2-8                        [32, 512, 7, 7]           --\n",
      "│    │    └─BasicBlock: 3-7                   [32, 512, 7, 7]           3,673,088\n",
      "│    │    └─BasicBlock: 3-8                   [32, 512, 7, 7]           4,720,640\n",
      "│    └─AdaptiveAvgPool2d: 2-9                 [32, 512, 1, 1]           --\n",
      "│    └─Identity: 2-10                         [32, 512]                 --\n",
      "├─ModuleList: 1-1                             --                        --\n",
      "│    └─Linear: 2-11                           [32, 4]                   2,052\n",
      "===============================================================================================\n",
      "Total params: 11,178,564\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 58.03\n",
      "===============================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 1271.66\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 1335.64\n",
      "===============================================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MultiTaskModelWrapper                    7\n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_ft, input_size=(32, 3, 224, 224), sampling=\"POP\"))\n",
    "print(summary(loss_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e18c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    loss_model,\n",
    "    criterion,\n",
    "    train_dataloaders,\n",
    "    test_dataloaders,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mean_UAR,\n",
    "    std_UAR,\n",
    "    mean_POP,\n",
    "    std_POP,\n",
    "    num_epochs=50,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "):\n",
    "    since = time.time()\n",
    "    summary_writer = SummaryWriter(Path(log_loc)/\"1234\")\n",
    "    global_step = 0\n",
    "    \n",
    "    preds = {}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.debug(\"Using torch.device: {}\".format(device))\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.debug(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        logger.debug(\"-\" * 10)\n",
    "        \n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            all_labels = {sample : [] for sample in tasks}\n",
    "            all_predictions = {sample : [] for sample in tasks}\n",
    "            all_ids = {sample : [] for sample in tasks}\n",
    "\n",
    "            counter = 0\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            summary_writer.add_scalar(\n",
    "                tag=\"learning_rate\", scalar_value=lr, global_step=global_step\n",
    "            )\n",
    "\n",
    "            dataloaders = train_dataloaders if phase == \"train\" else test_dataloaders\n",
    "\n",
    "            num_batches = len(dataloaders[\"UAR\"])\n",
    "            logger.debug(\"Total batches: {}\".format(num_batches))\n",
    "            end_time = time.time()\n",
    "            debug_time = time.time()\n",
    "            \n",
    "            for data_UAR, data_POP in tqdm(tzip(dataloaders[\"UAR\"], dataloaders[\"POP\"]), total=num_batches):\n",
    "                counter += 1\n",
    "                global_step += 1\n",
    "                \n",
    "                ids_UAR, inputs_UAR, labels_UAR = data_UAR\n",
    "                ids_POP, inputs_POP, labels_POP = data_POP\n",
    "\n",
    "\n",
    "                for i in range(len(tasks_UAR)):\n",
    "                    all_labels[tasks_UAR[i]] += list(np.vstack(labels_UAR.numpy()[:,i]))\n",
    "                    all_ids[tasks_UAR[i]] += list(ids_POP)\n",
    "                    \n",
    "                for i in range(len(tasks_POP)):\n",
    "                    all_labels[tasks_POP[i]] += list(np.vstack(labels_POP.numpy()[:,i]))\n",
    "                    all_ids[tasks_POP[i]] += list(ids_POP)\n",
    "\n",
    "                inputs_UAR = inputs_UAR.float()\n",
    "                labels_UAR = labels_UAR.float()\n",
    "                inputs_UAR = inputs_UAR.to(device)\n",
    "                labels_UAR = labels_UAR.to(device)\n",
    "                \n",
    "                inputs_POP = inputs_POP.float()\n",
    "                labels_POP = labels_POP.float()\n",
    "                inputs_POP = inputs_POP.to(device)\n",
    "                labels_POP = labels_POP.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs_UAR = model.forward(inputs, \"UAR\")\n",
    "                    outputs_POP = model.forward(inputs, \"POP\")\n",
    "\n",
    "                    for i in range(len(tasks_UAR)):\n",
    "                        all_predictions[tasks_UAR[i]] += list(outputs_UAR.detach().cpu().numpy()[:,i])\n",
    "\n",
    "                    for i in range(len(tasks_POP)):\n",
    "                        all_predictions[tasks_POP[i]] += list(outputs_POP.detach().cpu().numpy()[:,i])\n",
    "\n",
    "                    loss_UAR = loss_model.forward(outputs_UAR, labels_UAR, criterion, \"UAR\")\n",
    "                    loss_POP = loss_model.forward(outputs_POP, labels_POP, criterion, \"POP\")\n",
    "                    loss = loss_UAR + loss_POP\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        summary_writer.add_scalar(\n",
    "                            tag=\"train_loss\",\n",
    "                            scalar_value=loss.item(),\n",
    "                            global_step=global_step,\n",
    "                        )\n",
    "                    else:\n",
    "                        summary_writer.add_scalar(\n",
    "                            tag=\"val_loss\",\n",
    "                            scalar_value=loss.item(),\n",
    "                            global_step=global_step,\n",
    "                        )\n",
    "                yeet = 100\n",
    "                if counter % yeet == 0:\n",
    "                    logger.debug(\"Time for {} batches: {}. Loss: {}\".format(yeet, time.time() - debug_time, loss.item()))\n",
    "                    debug_time = time.time()\n",
    "\n",
    "            # Testin some stuff here\n",
    "            for i in range(len(tasks_UAR)):\n",
    "                samp = tasks_UAR[i]\n",
    "                temp_labels = np.array(all_labels[samp])\n",
    "                temp_pred = np.array(all_predictions[samp])\n",
    "                \n",
    "                mask = !np.isnan(temp_labels)\n",
    "                temp_pred = temp_pred[mask]\n",
    "                temp_labels = temp_labels[mask]\n",
    "                \n",
    "                temp_pred = temp_pred * std_UAR[i] + mean_UAR[i]\n",
    "                temp_labels = temp_labels * std_UAR[i] + mean_UAR[i]\n",
    "                \n",
    "                r2_score = sklearn.metrics.r2_score(temp_labels, temp_pred)\n",
    "                logger.debug(\"Aggregate R2 for {0}: {1}\".format(samp, r2_score)\n",
    "\n",
    "            for i in range(len(tasks_POP)):\n",
    "                samp = tasks_POP[i]\n",
    "                temp_labels = np.array(all_labels[samp])\n",
    "                temp_pred = np.array(all_predictions[samp])\n",
    "                \n",
    "                mask = !np.isnan(temp_labels)\n",
    "                temp_pred = temp_pred[mask]\n",
    "                temp_labels = temp_labels[mask]\n",
    "                \n",
    "                temp_pred = temp_pred * std_POP[i] + mean_POP[i]\n",
    "                temp_labels = temp_labels * std_POP[i] + mean_POP[i]\n",
    "                \n",
    "                r2_score = sklearn.metrics.r2_score(temp_labels, temp_pred)\n",
    "                logger.debug(\"Aggregate R2 for {0}: {1}\".format(samp, r2_score)\n",
    "\n",
    "            logger.debug(\n",
    "                \"Epoch {0} Phase {1} complete\".format(epoch, phase)\n",
    "            )\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    logger.debug(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994ecfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    ids_train_UAR,\n",
    "    Y_train_UAR,\n",
    "    ids_test_UAR,\n",
    "    Y_test_UAR,\n",
    "    ids_train_POP,\n",
    "    Y_train_POP,\n",
    "    ids_test_POP,\n",
    "    Y_test_POP,\n",
    "    model,\n",
    "    data_home_UAR,\n",
    "    data_home_POP,\n",
    "    loss,\n",
    "    num_epochs=25,\n",
    "    initial_lr=0.001,\n",
    "    log_loc=\"./pytorch.logs\",\n",
    "    save_dir=Path(c.data_dir)/\"int\"/\"deep_models\",\n",
    "    batch_size=32,\n",
    "):\n",
    "    mean_UAR = np.nanmean(Y_train_UAR, axis=0)\n",
    "    std_UAR = np.nanstd(Y_train_UAR, axis=0)\n",
    "    Y_train_UAR = (Y_train_UAR - mean_UAR) / std_UAR\n",
    "    Y_test_UAR = (Y_test_UAR - mean_UAR) / std_UAR\n",
    "    \n",
    "    mean_POP = np.nanmean(Y_train_POP, axis=0)\n",
    "    std_POP = np.nanstd(Y_train_POP, axis=0)\n",
    "    Y_train_POP = (Y_train_POP - mean_POP) / std_POP\n",
    "    Y_test_POP = (Y_test_POP - mean_POP) / std_POP\n",
    "    \n",
    "    train_dataloaders = {}\n",
    "    test_dataloaders = {}\n",
    "    \n",
    "    train_dataloaders[\"UAR\"] = get_dataloader(\n",
    "        data_home_UAR,\n",
    "        Y_train_UAR,\n",
    "        ids_train_UAR,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    test_dataloaders[\"UAR\"] = get_dataloader(\n",
    "        data_home_UAR,\n",
    "        Y_test_UAR,\n",
    "        ids_test_UAR,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    train_dataloaders[\"POP\"] = get_dataloader(\n",
    "        data_home_POP,\n",
    "        Y_train_POP,\n",
    "        ids_train_POP,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    test_dataloaders[\"POP\"] = get_dataloader(\n",
    "        data_home_POP,\n",
    "        Y_test_POP,\n",
    "        ids_test_POP,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    if loss == \"mse\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        criterion = torch.nn.L1Loss()\n",
    "        \n",
    "    loss_model = MultiTaskModelWrapper()\n",
    "        \n",
    "    optimizer_ft = torch.optim.SGD(list(model.parameters()) + list(loss_model.parameters()), lr=initial_lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_ft, milestones=[10], gamma=0.5)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    return train_model(\n",
    "        model,\n",
    "        loss_model,\n",
    "        criterion,\n",
    "        train_dataloaders,\n",
    "        test_dataloaders,\n",
    "        optimizer_ft,\n",
    "        scheduler,\n",
    "        mean_UAR,\n",
    "        std_UAR,\n",
    "        mean_POP,\n",
    "        std_POP,\n",
    "        num_epochs=num_epochs,\n",
    "        log_loc=log_loc,\n",
    "        save_dir=save_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024ce9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 23:11:42.138 | DEBUG    | __main__:train_model:23 - Using torch.device: cuda:0\n",
      "2022-05-24 23:11:42.139 | DEBUG    | __main__:train_model:25 - Epoch 1/2\n",
      "2022-05-24 23:11:42.140 | DEBUG    | __main__:train_model:26 - ----------\n",
      "2022-05-24 23:11:42.144 | DEBUG    | __main__:train_model:47 - Total batches: 2500\n",
      "  0%|                                                                                                                               | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27cddd465fc406c8232db8386ff3428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▋                                                                                                                 | 99/2500 [01:15<26:37,  1.50it/s]2022-05-24 23:12:57.835 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 75.68871355056763\n",
      "  8%|█████████▎                                                                                                           | 199/2500 [02:27<29:38,  1.29it/s]2022-05-24 23:14:10.280 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.44238996505737\n",
      " 12%|█████████████▉                                                                                                       | 299/2500 [03:39<25:29,  1.44it/s]2022-05-24 23:15:22.280 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.99545693397522\n",
      " 16%|██████████████████▋                                                                                                  | 399/2500 [04:51<26:24,  1.33it/s]2022-05-24 23:16:33.720 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.43784832954407\n",
      " 20%|███████████████████████▎                                                                                             | 499/2500 [06:02<25:34,  1.30it/s]2022-05-24 23:17:45.530 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.79344725608826\n",
      " 24%|████████████████████████████                                                                                         | 599/2500 [07:14<24:19,  1.30it/s]2022-05-24 23:18:57.413 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.87660312652588\n",
      " 28%|████████████████████████████████▋                                                                                    | 699/2500 [08:25<21:42,  1.38it/s]2022-05-24 23:20:08.164 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.7322690486908\n",
      " 32%|█████████████████████████████████████▍                                                                               | 799/2500 [09:37<20:20,  1.39it/s]2022-05-24 23:21:19.895 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.72891497612\n",
      " 36%|██████████████████████████████████████████                                                                           | 899/2500 [10:49<19:22,  1.38it/s]2022-05-24 23:22:31.706 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.79661154747009\n",
      " 40%|██████████████████████████████████████████████▊                                                                      | 999/2500 [12:01<17:01,  1.47it/s]2022-05-24 23:23:44.064 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.33227491378784\n",
      " 44%|██████████████████████████████████████████████████▉                                                                 | 1099/2500 [13:13<16:16,  1.44it/s]2022-05-24 23:24:55.708 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.63626313209534\n",
      " 48%|███████████████████████████████████████████████████████▋                                                            | 1199/2500 [14:24<14:48,  1.47it/s]2022-05-24 23:26:06.958 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.2409873008728\n",
      " 52%|████████████████████████████████████████████████████████████▎                                                       | 1299/2500 [15:35<12:53,  1.55it/s]2022-05-24 23:27:18.543 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.57855725288391\n",
      " 60%|█████████████████████████████████████████████████████████████████████▌                                              | 1499/2500 [17:59<11:18,  1.48it/s]2022-05-24 23:29:42.545 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.12746906280518\n",
      " 64%|██████████████████████████████████████████████████████████████████████████▏                                         | 1599/2500 [19:11<10:40,  1.41it/s]2022-05-24 23:30:53.707 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.15067768096924\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████▊                                     | 1699/2500 [20:22<09:05,  1.47it/s]2022-05-24 23:32:05.036 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.32249712944031\n",
      " 72%|███████████████████████████████████████████████████████████████████████████████████▍                                | 1799/2500 [21:34<08:24,  1.39it/s]2022-05-24 23:33:16.814 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.767263174057\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████                            | 1899/2500 [22:44<06:49,  1.47it/s]2022-05-24 23:34:27.563 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.74067497253418\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████▊                       | 1999/2500 [24:00<05:27,  1.53it/s]2022-05-24 23:35:43.172 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 75.60398721694946\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 2099/2500 [25:12<05:04,  1.32it/s]2022-05-24 23:36:55.299 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.11056518554688\n",
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████              | 2199/2500 [26:24<03:30,  1.43it/s]2022-05-24 23:38:07.127 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.8260190486908\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 2299/2500 [27:35<02:12,  1.52it/s]2022-05-24 23:39:18.000 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.86345314979553\n",
      " 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 2399/2500 [28:45<01:07,  1.51it/s]2022-05-24 23:40:28.633 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.62373924255371\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2499/2500 [29:56<00:00,  1.99it/s]2022-05-24 23:41:39.229 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.59416007995605\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [29:57<00:00,  1.39it/s]\n",
      "2022-05-24 23:41:39.367 | DEBUG    | __main__:train_model:123 - Epoch 0 Phase train of POP complete, Aggregate R2 Score of treecover: 0.061537394207410556\n",
      "2022-05-24 23:41:39.482 | DEBUG    | __main__:train_model:47 - Total batches: 625\n",
      "  0%|                                                                                                                                | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0528d6d95c452692fc68cc6697f227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▊                                                                                                    | 99/625 [01:10<05:18,  1.65it/s]2022-05-24 23:42:50.214 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.72979784011841\n",
      " 32%|█████████████████████████████████████▌                                                                                | 199/625 [02:16<03:59,  1.78it/s]2022-05-24 23:43:56.342 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 66.11959648132324\n",
      " 48%|████████████████████████████████████████████████████████▍                                                             | 299/625 [03:24<03:28,  1.56it/s]2022-05-24 23:45:04.326 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 67.96169519424438\n",
      " 64%|███████████████████████████████████████████████████████████████████████████▎                                          | 399/625 [04:30<02:05,  1.80it/s]2022-05-24 23:46:10.246 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 65.91493773460388\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████▏                       | 499/625 [05:38<01:12,  1.75it/s]2022-05-24 23:47:18.088 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 67.83814215660095\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 599/625 [06:45<00:15,  1.68it/s]2022-05-24 23:48:24.686 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 66.59587287902832\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [07:01<00:00,  1.48it/s]\n",
      "2022-05-24 23:48:40.558 | DEBUG    | __main__:train_model:123 - Epoch 0 Phase test of POP complete, Aggregate R2 Score of treecover: 0.004562816582710294\n",
      "2022-05-24 23:48:40.559 | DEBUG    | __main__:train_model:25 - Epoch 2/2\n",
      "2022-05-24 23:48:40.560 | DEBUG    | __main__:train_model:26 - ----------\n",
      "2022-05-24 23:48:40.581 | DEBUG    | __main__:train_model:47 - Total batches: 2500\n",
      "  0%|                                                                                                                               | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d735e4dc145aa88fcd3b7de88bfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▋                                                                                                                 | 99/2500 [01:13<26:15,  1.52it/s]2022-05-24 23:49:54.808 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 74.22548222541809\n",
      "  8%|█████████▎                                                                                                           | 199/2500 [02:23<25:04,  1.53it/s]2022-05-24 23:51:04.944 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.13381695747375\n",
      " 12%|█████████████▉                                                                                                       | 299/2500 [03:33<23:38,  1.55it/s]2022-05-24 23:52:14.862 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 69.9090781211853\n",
      " 16%|██████████████████▋                                                                                                  | 399/2500 [04:45<23:16,  1.50it/s]2022-05-24 23:53:26.092 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.21549344062805\n",
      " 20%|███████████████████████▎                                                                                             | 499/2500 [05:53<22:06,  1.51it/s]2022-05-24 23:54:35.052 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 68.95316791534424\n",
      " 24%|████████████████████████████                                                                                         | 599/2500 [07:03<21:05,  1.50it/s]2022-05-24 23:55:44.704 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 69.64996719360352\n",
      " 28%|████████████████████████████████▋                                                                                    | 699/2500 [08:13<19:33,  1.53it/s]2022-05-24 23:56:54.945 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.22985482215881\n",
      " 32%|█████████████████████████████████████▍                                                                               | 799/2500 [09:23<18:00,  1.57it/s]2022-05-24 23:58:05.504 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.55332088470459\n",
      " 36%|██████████████████████████████████████████                                                                           | 899/2500 [10:34<21:28,  1.24it/s]2022-05-24 23:59:15.543 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.0357391834259\n",
      " 40%|██████████████████████████████████████████████▊                                                                      | 999/2500 [11:45<20:16,  1.23it/s]2022-05-25 00:00:26.980 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.41938781738281\n",
      " 44%|██████████████████████████████████████████████████▉                                                                 | 1099/2500 [12:55<19:05,  1.22it/s]2022-05-25 00:01:37.056 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.07385730743408\n",
      " 48%|███████████████████████████████████████████████████████▋                                                            | 1199/2500 [14:07<15:58,  1.36it/s]2022-05-25 00:02:48.076 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.01596212387085\n",
      " 52%|████████████████████████████████████████████████████████████▎                                                       | 1299/2500 [15:17<15:19,  1.31it/s]2022-05-25 00:03:58.611 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.53339886665344\n",
      " 56%|████████████████████████████████████████████████████████████████▉                                                   | 1399/2500 [16:26<13:50,  1.33it/s]2022-05-25 00:05:07.992 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 69.36749935150146\n",
      " 60%|█████████████████████████████████████████████████████████████████████▌                                              | 1499/2500 [17:37<12:45,  1.31it/s]2022-05-25 00:06:18.449 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.44102835655212\n",
      " 64%|██████████████████████████████████████████████████████████████████████████▏                                         | 1599/2500 [18:49<12:50,  1.17it/s]2022-05-25 00:07:30.848 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.39502429962158\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████▊                                     | 1699/2500 [20:01<09:56,  1.34it/s]2022-05-25 00:08:42.458 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.60036492347717\n",
      " 72%|███████████████████████████████████████████████████████████████████████████████████▍                                | 1799/2500 [21:11<08:14,  1.42it/s]2022-05-25 00:09:52.492 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.0242977142334\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████                            | 1899/2500 [22:22<07:39,  1.31it/s]2022-05-25 00:11:03.457 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.96298289299011\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████▊                       | 1999/2500 [23:34<06:07,  1.36it/s]2022-05-25 00:12:15.469 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 72.01016640663147\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 2099/2500 [24:45<04:46,  1.40it/s]2022-05-25 00:13:26.085 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.60130500793457\n",
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████              | 2199/2500 [25:56<03:48,  1.31it/s]2022-05-25 00:14:37.316 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.21705770492554\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 2299/2500 [27:06<02:19,  1.44it/s]2022-05-25 00:15:47.400 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 70.07440996170044\n",
      " 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 2399/2500 [28:17<01:16,  1.33it/s]2022-05-25 00:16:59.026 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.62109398841858\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2499/2500 [29:29<00:00,  1.85it/s]2022-05-25 00:18:10.086 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.05248761177063\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [29:29<00:00,  1.41it/s]\n",
      "2022-05-25 00:18:10.229 | DEBUG    | __main__:train_model:123 - Epoch 1 Phase train of POP complete, Aggregate R2 Score of treecover: 0.10978309440903622\n",
      "2022-05-25 00:18:10.363 | DEBUG    | __main__:train_model:47 - Total batches: 625\n",
      "  0%|                                                                                                                                | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb57c8e7ff62415baf5d18baea0024d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▊                                                                                                    | 99/625 [01:11<05:07,  1.71it/s]2022-05-25 00:19:21.556 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 71.19178080558777\n",
      " 32%|█████████████████████████████████████▌                                                                                | 199/625 [02:18<03:56,  1.80it/s]2022-05-25 00:20:28.728 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 67.16684293746948\n",
      " 48%|████████████████████████████████████████████████████████▍                                                             | 299/625 [03:24<02:24,  2.25it/s]2022-05-25 00:21:36.673 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 67.94307112693787\n",
      " 64%|███████████████████████████████████████████████████████████████████████████▎                                          | 399/625 [04:32<01:45,  2.15it/s]2022-05-25 00:22:44.764 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 68.06745171546936\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████▏                       | 499/625 [05:40<00:57,  2.19it/s]2022-05-25 00:23:52.966 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 68.18964576721191\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 599/625 [06:47<00:11,  2.34it/s]2022-05-25 00:25:00.575 | DEBUG    | __main__:train_model:104 - Time for 100 batches: 67.5953540802002\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [07:04<00:00,  1.47it/s]\n",
      "2022-05-25 00:25:14.590 | DEBUG    | __main__:train_model:123 - Epoch 1 Phase test of POP complete, Aggregate R2 Score of treecover: -0.006749519048150132\n",
      "2022-05-25 00:25:14.590 | DEBUG    | __main__:train_model:130 - Training complete in 73m 32s\n"
     ]
    }
   ],
   "source": [
    "trained_model = run(ids_train_UAR,\n",
    "    Y_train_UAR,\n",
    "    ids_test_UAR,\n",
    "    Y_test_UAR,\n",
    "    ids_train_POP,\n",
    "    Y_train_POP,\n",
    "    ids_test_POP,\n",
    "    Y_test_POP,\n",
    "    MultiTaskModel(),\n",
    "    data_home_UAR,\n",
    "    data_home_POP,\n",
    "    'mse',\n",
    "    num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e075540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try save params\n",
    "model_param_path = c.code_dir + \"/cs230/temp_trained_params.pt\"\n",
    "torch.save(trained_model.state_dict(), model_param_path)\n",
    "\n",
    "# now try load\n",
    "loaded_model = MultiTaskModel()\n",
    "loaded_model.load_state_dict(torch.load(model_param_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f35593a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "MultiTaskModel                                --\n",
       "├─ResNet: 1-1                                 --\n",
       "│    └─Conv2d: 2-1                            9,408\n",
       "│    └─BatchNorm2d: 2-2                       128\n",
       "│    └─ReLU: 2-3                              --\n",
       "│    └─MaxPool2d: 2-4                         --\n",
       "│    └─Sequential: 2-5                        --\n",
       "│    │    └─BasicBlock: 3-1                   73,984\n",
       "│    │    └─BasicBlock: 3-2                   73,984\n",
       "│    └─Sequential: 2-6                        --\n",
       "│    │    └─BasicBlock: 3-3                   230,144\n",
       "│    │    └─BasicBlock: 3-4                   295,424\n",
       "│    └─Sequential: 2-7                        --\n",
       "│    │    └─BasicBlock: 3-5                   919,040\n",
       "│    │    └─BasicBlock: 3-6                   1,180,672\n",
       "│    └─Sequential: 2-8                        --\n",
       "│    │    └─BasicBlock: 3-7                   3,673,088\n",
       "│    │    └─BasicBlock: 3-8                   4,720,640\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 --\n",
       "│    └─Identity: 2-10                         --\n",
       "├─ModuleList: 1-2                             --\n",
       "│    └─Linear: 2-11                           1,539\n",
       "│    └─Linear: 2-12                           2,052\n",
       "======================================================================\n",
       "Total params: 11,180,103\n",
       "Trainable params: 11,180,103\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(trained_model)\n",
    "summary(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e72a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mosaiks-env)",
   "language": "python",
   "name": "conda_mosaiks-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
